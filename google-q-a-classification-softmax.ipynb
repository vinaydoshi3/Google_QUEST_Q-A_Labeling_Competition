{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/huggingface-transformers/sacremoses-master/sacremoses-master\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses==0.0.35) (1.13.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses==0.0.35) (7.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses==0.0.35) (0.14.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from sacremoses==0.0.35) (4.39.0)\r\n",
      "Building wheels for collected packages: sacremoses\r\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=882724 sha256=25ec6bafb72a99e2312141c6f1de8e672ecbaacd28415efeb16bbcfdf5155c18\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/b3/c1/90/fb74570cc1a23673f29766b39fa295da523fac9813fb3f32c9\r\n",
      "Successfully built sacremoses\r\n",
      "Installing collected packages: sacremoses\r\n",
      "Successfully installed sacremoses-0.0.35\r\n",
      "Processing /kaggle/input/huggingface-transformers/transformers-master/transformers-master\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.2) (1.17.4)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.2) (1.10.29)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.2) (2.22.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.2) (4.39.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.2) (2019.11.1)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.2) (0.1.83)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers==2.2.2) (0.0.35)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.2.2) (0.9.4)\r\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.2.2) (0.2.1)\r\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.29 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.2.2) (1.13.29)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.2.2) (3.0.4)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.2.2) (2.8)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.2.2) (2019.9.11)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.2.2) (1.24.2)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.2.2) (7.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.2.2) (1.13.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.2.2) (0.14.0)\r\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.29->boto3->transformers==2.2.2) (2.8.0)\r\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.29->boto3->transformers==2.2.2) (0.15.2)\r\n",
      "Building wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-2.2.2-cp36-none-any.whl size=415676 sha256=550cfa8d1a7521275e974f9149c9aaed12345745c844926ba992219e67d6f45c\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/7e/f5/40/5ef4fd8956cee49677c0bdfe569e8aa2cc7f2441e8bef98d1a\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: transformers\r\n",
      "Successfully installed transformers-2.2.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/huggingface-transformers/sacremoses-master/sacremoses-master\n",
    "!pip install ../input/huggingface-transformers/transformers-master/transformers-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af6d236ebd14aa4b0604846450d180d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "import bert_tokenization as tokenization\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from transformers import TFPreTrainedModel, TFBertPreTrainedModel, TFBertMainLayer, BertConfig, TFBertModel, BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers.modeling_tf_utils import get_initializer\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyprind \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import operator\n",
    "import string\n",
    "import json\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "# import pytorch_transformers\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# tf.executing_eagerly()\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Shape: (6079, 41)\n",
      "Test Shape: (476, 11)\n",
      "Df Shape:(6555, 41)\n",
      "\n",
      "output categories:\n",
      "\t ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
      "\n",
      "input categories:\n",
      "\t ['question_title', 'question_body', 'answer']\n"
     ]
    }
   ],
   "source": [
    "PATH = '../input/google-quest-challenge/'\n",
    "BERT_PATH = '../input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12'\n",
    "# tokenizer = tokenization.FullTokenizer(BERT_PATH+'/assets/vocab.txt', True)\n",
    "tokenizer2 = BertTokenizer.from_pretrained(BERT_PATH+'/assets/vocab.txt', do_lower_case=True,)\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "df_train = pd.read_csv(PATH+'train.csv',header=0,encoding='utf-8')\n",
    "df_test = pd.read_csv(PATH+'test.csv',header=0,encoding='utf-8')\n",
    "df_sub = pd.read_csv(PATH+'sample_submission.csv')\n",
    "df = pd.concat([df_train,df_test],axis=0,ignore_index=True)\n",
    "print(f'''Train Shape: {df_train.shape}\n",
    "Test Shape: {df_test.shape}\n",
    "Df Shape:{df.shape}''')\n",
    "\n",
    "\n",
    "output_categories = ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
    "input_categories = ['question_title', 'question_body', 'answer']\n",
    "print('\\noutput categories:\\n\\t', output_categories)\n",
    "print('\\ninput categories:\\n\\t', input_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_asker_intent_understanding: 9\n",
      "question_body_critical: 9\n",
      "question_conversational: 5\n",
      "question_expect_short_answer: 5\n",
      "question_fact_seeking: 5\n",
      "question_has_commonly_accepted_answer: 5\n",
      "question_interestingness_others: 9\n",
      "question_interestingness_self: 9\n",
      "question_multi_intent: 5\n",
      "question_not_really_a_question: 5\n",
      "question_opinion_seeking: 5\n",
      "question_type_choice: 5\n",
      "question_type_compare: 5\n",
      "question_type_consequence: 5\n",
      "question_type_definition: 5\n",
      "question_type_entity: 5\n",
      "question_type_instructions: 5\n",
      "question_type_procedure: 5\n",
      "question_type_reason_explanation: 5\n",
      "question_type_spelling: 3\n",
      "question_well_written: 9\n",
      "answer_helpful: 9\n",
      "answer_level_of_information: 9\n",
      "answer_plausible: 9\n",
      "answer_relevance: 9\n",
      "answer_satisfaction: 17\n",
      "answer_type_instructions: 5\n",
      "answer_type_procedure: 5\n",
      "answer_type_reason_explanation: 5\n",
      "answer_well_written: 9\n"
     ]
    }
   ],
   "source": [
    "for col in output_categories:\n",
    "    print(f'{col}: {len(df_train[col].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.88888889, 0.77777778, 0.83333333, 0.66666667,\n",
       "       0.5       , 0.55555556, 0.44444444, 0.33333333,        nan])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['answer_well_written'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3333333333333333,\n",
       " 0.4444444444444444,\n",
       " 0.5,\n",
       " 0.5555555555555556,\n",
       " 0.6666666666666666,\n",
       " 0.7777777777777778,\n",
       " 0.8333333333333334,\n",
       " 0.8888888888888888,\n",
       " 1.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df_train['answer_well_written'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_asker_intent_understanding:(6079, 9)\n",
      "question_body_critical:(6079, 9)\n",
      "question_conversational:(6079, 5)\n",
      "question_expect_short_answer:(6079, 5)\n",
      "question_fact_seeking:(6079, 5)\n",
      "question_has_commonly_accepted_answer:(6079, 5)\n",
      "question_interestingness_others:(6079, 9)\n",
      "question_interestingness_self:(6079, 9)\n",
      "question_multi_intent:(6079, 5)\n",
      "question_not_really_a_question:(6079, 5)\n",
      "question_opinion_seeking:(6079, 5)\n",
      "question_type_choice:(6079, 5)\n",
      "question_type_compare:(6079, 5)\n",
      "question_type_consequence:(6079, 5)\n",
      "question_type_definition:(6079, 5)\n",
      "question_type_entity:(6079, 5)\n",
      "question_type_instructions:(6079, 5)\n",
      "question_type_procedure:(6079, 5)\n",
      "question_type_reason_explanation:(6079, 5)\n",
      "question_type_spelling:(6079, 3)\n",
      "question_well_written:(6079, 9)\n",
      "answer_helpful:(6079, 9)\n",
      "answer_level_of_information:(6079, 9)\n",
      "answer_plausible:(6079, 9)\n",
      "answer_relevance:(6079, 9)\n",
      "answer_satisfaction:(6079, 17)\n",
      "answer_type_instructions:(6079, 5)\n",
      "answer_type_procedure:(6079, 5)\n",
      "answer_type_reason_explanation:(6079, 5)\n",
      "answer_well_written:(6079, 9)\n"
     ]
    }
   ],
   "source": [
    "dum_cols = {}\n",
    "for col in output_categories:\n",
    "    key = f'{col}'\n",
    "    dum_cols[key] = pd.get_dummies(df_train[col], drop_first=False, prefix=f'{col}')\n",
    "    print(f'{col}:{dum_cols[key].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_masks(tokens, max_seq_length):\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens)+[0]*(max_seq_length-len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length):\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    \n",
    "    segments=[]\n",
    "    first_sep=True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == '[ANS]':\n",
    "#             if first_sep:\n",
    "#                 first_sep=False\n",
    "#             else:\n",
    "            current_segment_id=1\n",
    "    return segments+[0]*(max_seq_length-len(tokens))\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length, t_max_len=30, q_max_len=239, a_max_len=239):\n",
    "\n",
    "    t = tokenizer2.tokenize(title)\n",
    "    q = tokenizer2.tokenize(question)\n",
    "    a = tokenizer2.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "        \n",
    "        t = t[:t_new_len]\n",
    "        q = q[:q_new_len]\n",
    "        a = a[:a_new_len]\n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0]*(max_seq_length - len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, tokenizer, max_seq_length):\n",
    "    stoken = ['[CLS]']+title+['[QBODY]']+question+['[ANS]']+answer+['[SEP]']\n",
    "    input_ids = _get_ids(tokens=stoken, tokenizer=tokenizer,max_seq_length=max_seq_length)\n",
    "    input_masks = _get_masks(tokens=stoken, max_seq_length=max_seq_length)\n",
    "    input_segments = _get_segments(tokens=stoken, max_seq_length=max_seq_length)\n",
    "    \n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def compute_input_array(df, columns, tokenizer, max_sequence_length):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for _, col in tqdm(df[columns].iterrows()):\n",
    "        t, q, a = col['question_title'], col['question_body'], col['answer']\n",
    "        t,q,a = _trim_input(t,q,a, max_sequence_length)\n",
    "        ids, masks, segments = _convert_to_bert_inputs(t,q,a, tokenizer, max_sequence_length)\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "        \n",
    "    return [np.array(input_ids, dtype=np.int32), np.array(input_masks, dtype=np.int32), \n",
    "            np.array(input_segments, dtype=np.int32)]\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearmanr(trues, preds):\n",
    "    rhos=[]\n",
    "    for t, p in zip(trues.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(t,p).correlation\n",
    "        )\n",
    "    return np.nanmean(rhos)\n",
    "\n",
    "test_predictions=[]\n",
    "\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, val_size,valid_data, test_data, test_predictions=test_predictions, batch_size=16, fold=None):\n",
    "        self.valid_inputs = valid_data[0]\n",
    "        self.valid_outputs = valid_data[1]\n",
    "        self.val_size = val_size\n",
    "        self.test_inputs = test_data\n",
    "        self.batch_size = batch_size\n",
    "        self.test_predictions = test_predictions\n",
    "        self.fold = fold\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.valid_predictions=[]\n",
    "        self.valid_preds = np.zeros((self.val_size, len(output_categories)), dtype=np.float64)\n",
    "        self.test_preds = np.zeros((len(self.test_inputs[0]), len(output_categories)), dtype=np.float64)\n",
    "        #self.test_predictions=[]\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        out=self.model.predict(self.valid_inputs, batch_size=self.batch_size)\n",
    "        \n",
    "#         valid_preds = np.zeros((self.val_size, len(output_categories)), dtype=np.float64)\n",
    "        for i,col in enumerate(output_categories):\n",
    "            for j in range(0,self.val_size):\n",
    "                self.valid_preds[j][i]=sorted(df_train[col].unique())[np.argmax(out[i][j])]\n",
    "        \n",
    "        self.valid_predictions.append(self.valid_preds)\n",
    "        \n",
    "        \n",
    "        \n",
    "        rho_val = compute_spearmanr(self.valid_outputs, np.average(self.valid_predictions, axis=0))\n",
    "        print(f\"\\nvalidation rho: {round(rho_val,4)}\")\n",
    "#         test_preds\n",
    "        test_out=self.model.predict(self.test_inputs, batch_size=self.batch_size)\n",
    "        for i,col in enumerate(output_categories):\n",
    "            for j in range(len(self.test_inputs[0])):\n",
    "                self.test_preds[j][i]=sorted(df_train[col].unique())[np.argmax(out[i][j])]\n",
    "        \n",
    "        self.test_predictions.append(self.test_preds)\n",
    "        \n",
    "#         self.model.save_weights(f'/kaggle/working/bert-base-{fold}-{epoch}.hdf5')\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_config=BertConfig(unk_token=\"[QBODY]\", pad_token=\"[ANS]\").from_pretrained('../input/bert-tensorflow/bert-base-uncased-config.json',output_hidden_states=True, num_labels=30)\n",
    "# def bertModel():\n",
    "#     input_ids = keras.layers.Input((MAX_SEQUENCE_LENGTH), dtype = tf.int32, name = 'input_word_ids')\n",
    "#     input_mask = keras.layers.Input((MAX_SEQUENCE_LENGTH), dtype = tf.int32, name = 'input_masks')\n",
    "#     input_segments = keras.layers.Input((MAX_SEQUENCE_LENGTH), dtype = tf.int32, name = 'input_segments')\n",
    "    \n",
    "#     bert_model = TFBertModel.from_pretrained(pretrained_model_name_or_path='../input/bert-tensorflow/bert-base-uncased-tf_model.h5',config = bert_config)\n",
    "# #     bert_model.resize_token_embeddings(len(tokenizer2))\n",
    "#     sequence_output, pooler_output, hidden_states = bert_model([input_ids,input_mask, input_segments])\n",
    "    \n",
    "#     h12 = tf.reshape(hidden_states[-1][:,0],(-1,1,768))\n",
    "#     h11 = tf.reshape(hidden_states[-2][:,0],(-1,1,768))\n",
    "#     h10 = tf.reshape(hidden_states[-3][:,0],(-1,1,768))\n",
    "#     h09 = tf.reshape(hidden_states[-4][:,0],(-1,1,768))\n",
    "#     concat_hidden = keras.layers.Concatenate(axis=2)([h12, h11, h10, h09])\n",
    "# #     concat_hidden = tf.reshape(concat_hidden, (-1,768*4))\n",
    "#     x = keras.layers.GlobalAveragePooling1D()(concat_hidden)\n",
    "# #     dense1 = keras.layers.Dense(768)(x)\n",
    "# #     dense1 = keras.layers.LeakyReLU()(dense1)\n",
    "# #     x = keras.layers.Add()([dense1,x])    \n",
    "#     x = keras.layers.Dropout(0.2)(x)\n",
    "#     out = keras.layers.Dense(len(output_categories), activation='sigmoid', name='final_dense_output')(x)\n",
    "    \n",
    "#     model = keras.models.Model(inputs=[input_ids, input_mask, input_segments], outputs=out)\n",
    "#     model.compile(loss='binary_crossentropy', optimizer = keras.optimizers.Adam(lr=3e-5))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config=BertConfig(unk_token=\"[QBODY]\", pad_token=\"[ANS]\").from_pretrained('../input/bert-tensorflow/bert-base-uncased-config.json',output_hidden_states=True, num_labels=30)\n",
    "\n",
    "def dense_layer(bert_in,units, name, activation='softmax'):\n",
    "    d = keras.layers.Dense(units, activation=activation, name=name)(bert_in)\n",
    "    return d\n",
    "\n",
    "def bertModel(output_categories=output_categories, dum_cols = dum_cols):\n",
    "    input_ids = keras.layers.Input((MAX_SEQUENCE_LENGTH), dtype = tf.int32, name = 'input_word_ids')\n",
    "    input_mask = keras.layers.Input((MAX_SEQUENCE_LENGTH), dtype = tf.int32, name = 'input_masks')\n",
    "    input_segments = keras.layers.Input((MAX_SEQUENCE_LENGTH), dtype = tf.int32, name = 'input_segments')\n",
    "    \n",
    "    bert_model = TFBertForSequenceClassification.from_pretrained(pretrained_model_name_or_path='../input/bert-tensorflow/bert-base-uncased-tf_model.h5',config = bert_config)\n",
    "#     bert_model.resize_token_embeddings(len(tokenizer2))\n",
    "    logits, hidden_states = bert_model([input_ids,input_mask, input_segments])\n",
    "    \n",
    "    h12 = tf.reshape(hidden_states[-1][:,0],(-1,1,768))\n",
    "    h11 = tf.reshape(hidden_states[-2][:,0],(-1,1,768))\n",
    "    h10 = tf.reshape(hidden_states[-3][:,0],(-1,1,768))\n",
    "    h09 = tf.reshape(hidden_states[-4][:,0],(-1,1,768))\n",
    "    concat_hidden = keras.layers.Concatenate(axis=2)([h12, h11, h10, h09])\n",
    "#     concat_hidden = tf.reshape(concat_hidden, (-1,768*4))\n",
    "    x = keras.layers.GlobalAveragePooling1D()(concat_hidden)\n",
    "# #     dense1 = keras.layers.Dense(768)(x)\n",
    "# #     dense1 = keras.layers.LeakyReLU()(dense1)\n",
    "# #     x = keras.layers.Add()([dense1,x])    \n",
    "#     x = keras.layers.Dropout(0.2)(x)\n",
    "    out = {}\n",
    "    for col in output_categories:\n",
    "        key=f'{col}'\n",
    "        out[key]=dense_layer(bert_in=x,units=dum_cols[key].shape[1], name=f'out_{col}', activation='softmax')\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_ids, input_mask, input_segments], \n",
    "                               outputs=[out['question_asker_intent_understanding'],\n",
    "                                        out['question_body_critical'],\n",
    "                                        out['question_conversational'],\n",
    "                                        out['question_expect_short_answer'],\n",
    "                                        out['question_fact_seeking'],\n",
    "                                        out['question_has_commonly_accepted_answer'],\n",
    "                                        out['question_interestingness_others'],\n",
    "                                        out['question_interestingness_self'],\n",
    "                                        out['question_multi_intent'],\n",
    "                                        out['question_not_really_a_question'],\n",
    "                                        out['question_opinion_seeking'],\n",
    "                                        out['question_type_choice'],\n",
    "                                        out['question_type_compare'],\n",
    "                                        out['question_type_consequence'],\n",
    "                                        out['question_type_definition'],\n",
    "                                        out['question_type_entity'],\n",
    "                                        out['question_type_instructions'],\n",
    "                                        out['question_type_procedure'],\n",
    "                                        out['question_type_reason_explanation'],\n",
    "                                        out['question_type_spelling'],\n",
    "                                        out['question_well_written'],\n",
    "                                        out['answer_helpful'],\n",
    "                                        out['answer_level_of_information'],\n",
    "                                        out['answer_plausible'],\n",
    "                                        out['answer_relevance'],\n",
    "                                        out['answer_satisfaction'],\n",
    "                                        out['answer_type_instructions'],\n",
    "                                        out['answer_type_procedure'],\n",
    "                                        out['answer_type_reason_explanation'],\n",
    "                                        out['answer_well_written']])\n",
    "                               \n",
    "    model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(lr=3e-5), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = bertModel()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qa_id', 'question_title', 'question_body', 'question_user_name',\n",
       "       'question_user_page', 'answer', 'answer_user_name', 'answer_user_page',\n",
       "       'url', 'category', 'host', 'question_asker_intent_understanding',\n",
       "       'question_body_critical', 'question_conversational',\n",
       "       'question_expect_short_answer', 'question_fact_seeking',\n",
       "       'question_has_commonly_accepted_answer',\n",
       "       'question_interestingness_others', 'question_interestingness_self',\n",
       "       'question_multi_intent', 'question_not_really_a_question',\n",
       "       'question_opinion_seeking', 'question_type_choice',\n",
       "       'question_type_compare', 'question_type_consequence',\n",
       "       'question_type_definition', 'question_type_entity',\n",
       "       'question_type_instructions', 'question_type_procedure',\n",
       "       'question_type_reason_explanation', 'question_type_spelling',\n",
       "       'question_well_written', 'answer_helpful',\n",
       "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
       "       'answer_satisfaction', 'answer_type_instructions',\n",
       "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
       "       'answer_well_written'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6079it [01:19, 76.54it/s]\n",
      "476it [00:06, 74.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# gkf = GroupKFold(n_splits=10).split(X=df_train.question_body, groups=df_train.question_body)\n",
    "\n",
    "outputs = compute_output_arrays(df_train, output_categories)\n",
    "inputs = compute_input_array(df_train, input_categories, tokenizer2, MAX_SEQUENCE_LENGTH)\n",
    "test_inputs = compute_input_array(df_test, input_categories, tokenizer2, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=10).split(X=df_train.question_body, groups=df_train.question_body)\n",
    "# train, valid, y_train, y_val = train_test_split(inputs, outputs, test_size=0.15, stratify=df_train['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H = model.fit(inputs, [dum_cols['question_asker_intent_understanding'],\n",
    "#  dum_cols['question_body_critical'],\n",
    "#  dum_cols['question_conversational'],\n",
    "#  dum_cols['question_expect_short_answer'],\n",
    "#  dum_cols['question_fact_seeking'],\n",
    "#  dum_cols['question_has_commonly_accepted_answer'],\n",
    "#  dum_cols['question_interestingness_others'],\n",
    "#  dum_cols['question_interestingness_self'],\n",
    "#  dum_cols['question_multi_intent'],\n",
    "#  dum_cols['question_not_really_a_question'],\n",
    "#  dum_cols['question_opinion_seeking'],\n",
    "#  dum_cols['question_type_choice'],\n",
    "#  dum_cols['question_type_compare'],\n",
    "#  dum_cols['question_type_consequence'],\n",
    "#  dum_cols['question_type_definition'],\n",
    "#  dum_cols['question_type_entity'],\n",
    "#  dum_cols['question_type_instructions'],\n",
    "#  dum_cols['question_type_procedure'],\n",
    "#  dum_cols['question_type_reason_explanation'],\n",
    "#  dum_cols['question_type_spelling'],\n",
    "#  dum_cols['question_well_written'],\n",
    "#  dum_cols['answer_helpful'],\n",
    "#  dum_cols['answer_level_of_information'],\n",
    "#  dum_cols['answer_plausible'],\n",
    "#  dum_cols['answer_relevance'],\n",
    "#  dum_cols['answer_satisfaction'],\n",
    "#  dum_cols['answer_type_instructions'],\n",
    "#  dum_cols['answer_type_procedure'],\n",
    "#  dum_cols['answer_type_reason_explanation'],\n",
    "#  dum_cols['answer_well_written']], batch_size=8, epochs=2, validation_split=0.15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5471 samples\n",
      "Epoch 1/4\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 31.5488 - out_question_asker_intent_understanding_loss: 1.4043 - out_question_body_critical_loss: 1.9169 - out_question_conversational_loss: 0.4044 - out_question_expect_short_answer_loss: 1.3659 - out_question_fact_seeking_loss: 1.1197 - out_question_has_commonly_accepted_answer_loss: 0.9997 - out_question_interestingness_others_loss: 1.6959 - out_question_interestingness_self_loss: 1.6798 - out_question_multi_intent_loss: 1.1369 - out_question_not_really_a_question_loss: 0.0752 - out_question_opinion_seeking_loss: 1.4171 - out_question_type_choice_loss: 1.1389 - out_question_type_compare_loss: 0.3179 - out_question_type_consequence_loss: 0.1256 - out_question_type_definition_loss: 0.2391 - out_question_type_entity_loss: 0.4516 - out_question_type_instructions_loss: 1.1028 - out_question_type_procedure_loss: 0.9953 - out_question_type_reason_explanation_loss: 1.2936 - out_question_type_spelling_loss: 0.0272 - out_question_well_written_loss: 1.8082 - out_answer_helpful_loss: 1.2257 - out_answer_level_of_information_loss: 1.2158 - out_answer_plausible_loss: 0.8551 - out_answer_relevance_loss: 0.7522 - out_answer_satisfaction_loss: 2.1251 - out_answer_type_instructions_loss: 1.1238 - out_answer_type_procedure_loss: 0.8788 - out_answer_type_reason_explanation_loss: 1.3116 - out_answer_well_written_loss: 1.3449 - out_question_asker_intent_understanding_accuracy: 0.4520 - out_question_body_critical_accuracy: 0.2555 - out_question_conversational_accuracy: 0.8915 - out_question_expect_short_answer_accuracy: 0.4731 - out_question_fact_seeking_accuracy: 0.5664 - out_question_has_commonly_accepted_answer_accuracy: 0.6814 - out_question_interestingness_others_accuracy: 0.2906 - out_question_interestingness_self_accuracy: 0.3569 - out_question_multi_intent_accuracy: 0.5899 - out_question_not_really_a_question_accuracy: 0.9887 - out_question_opinion_seeking_accuracy: 0.3536 - out_question_type_choice_accuracy: 0.5717 - out_question_type_compare_accuracy: 0.9284 - out_question_type_consequence_accuracy: 0.9777 - out_question_type_definition_accuracy: 0.9385 - out_question_type_entity_accuracy: 0.8852 - out_question_type_instructions_accuracy: 0.5781 - out_question_type_procedure_accuracy: 0.6316 - out_question_type_reason_explanation_accuracy: 0.4499 - out_question_type_spelling_accuracy: 0.9940 - out_question_well_written_accuracy: 0.2718 - out_answer_helpful_accuracy: 0.5955 - out_answer_level_of_information_accuracy: 0.6759 - out_answer_plausible_accuracy: 0.7710 - out_answer_relevance_accuracy: 0.8016 - out_answer_satisfaction_accuracy: 0.2123 - out_answer_type_instructions_accuracy: 0.5772 - out_answer_type_procedure_accuracy: 0.6938 - out_answer_type_reason_explanation_accuracy: 0.4610 - out_answer_well_written_accuracy: 0.4050\n",
      "validation rho: 0.3501\n",
      "5471/5471 [==============================] - 462s 84ms/sample - loss: 31.5460 - out_question_asker_intent_understanding_loss: 1.4039 - out_question_body_critical_loss: 1.9172 - out_question_conversational_loss: 0.4038 - out_question_expect_short_answer_loss: 1.3658 - out_question_fact_seeking_loss: 1.1190 - out_question_has_commonly_accepted_answer_loss: 0.9992 - out_question_interestingness_others_loss: 1.6952 - out_question_interestingness_self_loss: 1.6796 - out_question_multi_intent_loss: 1.1368 - out_question_not_really_a_question_loss: 0.0751 - out_question_opinion_seeking_loss: 1.4169 - out_question_type_choice_loss: 1.1390 - out_question_type_compare_loss: 0.3175 - out_question_type_consequence_loss: 0.1263 - out_question_type_definition_loss: 0.2398 - out_question_type_entity_loss: 0.4519 - out_question_type_instructions_loss: 1.1032 - out_question_type_procedure_loss: 0.9959 - out_question_type_reason_explanation_loss: 1.2933 - out_question_type_spelling_loss: 0.0271 - out_question_well_written_loss: 1.8083 - out_answer_helpful_loss: 1.2250 - out_answer_level_of_information_loss: 1.2145 - out_answer_plausible_loss: 0.8552 - out_answer_relevance_loss: 0.7514 - out_answer_satisfaction_loss: 2.1247 - out_answer_type_instructions_loss: 1.1240 - out_answer_type_procedure_loss: 0.8794 - out_answer_type_reason_explanation_loss: 1.3115 - out_answer_well_written_loss: 1.3448 - out_question_asker_intent_understanding_accuracy: 0.4524 - out_question_body_critical_accuracy: 0.2555 - out_question_conversational_accuracy: 0.8916 - out_question_expect_short_answer_accuracy: 0.4730 - out_question_fact_seeking_accuracy: 0.5668 - out_question_has_commonly_accepted_answer_accuracy: 0.6816 - out_question_interestingness_others_accuracy: 0.2910 - out_question_interestingness_self_accuracy: 0.3566 - out_question_multi_intent_accuracy: 0.5898 - out_question_not_really_a_question_accuracy: 0.9887 - out_question_opinion_seeking_accuracy: 0.3539 - out_question_type_choice_accuracy: 0.5716 - out_question_type_compare_accuracy: 0.9285 - out_question_type_consequence_accuracy: 0.9775 - out_question_type_definition_accuracy: 0.9384 - out_question_type_entity_accuracy: 0.8852 - out_question_type_instructions_accuracy: 0.5778 - out_question_type_procedure_accuracy: 0.6311 - out_question_type_reason_explanation_accuracy: 0.4500 - out_question_type_spelling_accuracy: 0.9940 - out_question_well_written_accuracy: 0.2714 - out_answer_helpful_accuracy: 0.5957 - out_answer_level_of_information_accuracy: 0.6763 - out_answer_plausible_accuracy: 0.7710 - out_answer_relevance_accuracy: 0.8019 - out_answer_satisfaction_accuracy: 0.2122 - out_answer_type_instructions_accuracy: 0.5769 - out_answer_type_procedure_accuracy: 0.6935 - out_answer_type_reason_explanation_accuracy: 0.4610 - out_answer_well_written_accuracy: 0.4047\n",
      "Epoch 2/4\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 29.1087 - out_question_asker_intent_understanding_loss: 1.3428 - out_question_body_critical_loss: 1.7784 - out_question_conversational_loss: 0.3550 - out_question_expect_short_answer_loss: 1.3173 - out_question_fact_seeking_loss: 1.0360 - out_question_has_commonly_accepted_answer_loss: 0.9213 - out_question_interestingness_others_loss: 1.6435 - out_question_interestingness_self_loss: 1.5979 - out_question_multi_intent_loss: 1.0280 - out_question_not_really_a_question_loss: 0.0638 - out_question_opinion_seeking_loss: 1.3174 - out_question_type_choice_loss: 0.9122 - out_question_type_compare_loss: 0.2580 - out_question_type_consequence_loss: 0.1057 - out_question_type_definition_loss: 0.1808 - out_question_type_entity_loss: 0.3720 - out_question_type_instructions_loss: 0.9429 - out_question_type_procedure_loss: 0.9395 - out_question_type_reason_explanation_loss: 1.1132 - out_question_type_spelling_loss: 0.0142 - out_question_well_written_loss: 1.7098 - out_answer_helpful_loss: 1.1624 - out_answer_level_of_information_loss: 1.1358 - out_answer_plausible_loss: 0.8188 - out_answer_relevance_loss: 0.7025 - out_answer_satisfaction_loss: 2.0470 - out_answer_type_instructions_loss: 0.9938 - out_answer_type_procedure_loss: 0.8406 - out_answer_type_reason_explanation_loss: 1.1678 - out_answer_well_written_loss: 1.2905 - out_question_asker_intent_understanding_accuracy: 0.4671 - out_question_body_critical_accuracy: 0.3044 - out_question_conversational_accuracy: 0.8918 - out_question_expect_short_answer_accuracy: 0.4753 - out_question_fact_seeking_accuracy: 0.5864 - out_question_has_commonly_accepted_answer_accuracy: 0.7035 - out_question_interestingness_others_accuracy: 0.3146 - out_question_interestingness_self_accuracy: 0.3849 - out_question_multi_intent_accuracy: 0.6105 - out_question_not_really_a_question_accuracy: 0.9896 - out_question_opinion_seeking_accuracy: 0.4114 - out_question_type_choice_accuracy: 0.6398 - out_question_type_compare_accuracy: 0.9339 - out_question_type_consequence_accuracy: 0.9797 - out_question_type_definition_accuracy: 0.9447 - out_question_type_entity_accuracy: 0.8887 - out_question_type_instructions_accuracy: 0.6349 - out_question_type_procedure_accuracy: 0.6345 - out_question_type_reason_explanation_accuracy: 0.5353 - out_question_type_spelling_accuracy: 0.9980 - out_question_well_written_accuracy: 0.3053 - out_answer_helpful_accuracy: 0.6041 - out_answer_level_of_information_accuracy: 0.6779 - out_answer_plausible_accuracy: 0.7743 - out_answer_relevance_accuracy: 0.8066 - out_answer_satisfaction_accuracy: 0.2304 - out_answer_type_instructions_accuracy: 0.6179 - out_answer_type_procedure_accuracy: 0.6944 - out_answer_type_reason_explanation_accuracy: 0.5201 - out_answer_well_written_accuracy: 0.4423\n",
      "validation rho: 0.3812\n",
      "5471/5471 [==============================] - 428s 78ms/sample - loss: 29.1094 - out_question_asker_intent_understanding_loss: 1.3421 - out_question_body_critical_loss: 1.7785 - out_question_conversational_loss: 0.3549 - out_question_expect_short_answer_loss: 1.3178 - out_question_fact_seeking_loss: 1.0356 - out_question_has_commonly_accepted_answer_loss: 0.9228 - out_question_interestingness_others_loss: 1.6437 - out_question_interestingness_self_loss: 1.5988 - out_question_multi_intent_loss: 1.0276 - out_question_not_really_a_question_loss: 0.0637 - out_question_opinion_seeking_loss: 1.3176 - out_question_type_choice_loss: 0.9134 - out_question_type_compare_loss: 0.2577 - out_question_type_consequence_loss: 0.1062 - out_question_type_definition_loss: 0.1806 - out_question_type_entity_loss: 0.3718 - out_question_type_instructions_loss: 0.9423 - out_question_type_procedure_loss: 0.9400 - out_question_type_reason_explanation_loss: 1.1130 - out_question_type_spelling_loss: 0.0142 - out_question_well_written_loss: 1.7094 - out_answer_helpful_loss: 1.1618 - out_answer_level_of_information_loss: 1.1357 - out_answer_plausible_loss: 0.8183 - out_answer_relevance_loss: 0.7022 - out_answer_satisfaction_loss: 2.0468 - out_answer_type_instructions_loss: 0.9933 - out_answer_type_procedure_loss: 0.8414 - out_answer_type_reason_explanation_loss: 1.1678 - out_answer_well_written_loss: 1.2902 - out_question_asker_intent_understanding_accuracy: 0.4672 - out_question_body_critical_accuracy: 0.3043 - out_question_conversational_accuracy: 0.8918 - out_question_expect_short_answer_accuracy: 0.4751 - out_question_fact_seeking_accuracy: 0.5864 - out_question_has_commonly_accepted_answer_accuracy: 0.7030 - out_question_interestingness_others_accuracy: 0.3146 - out_question_interestingness_self_accuracy: 0.3846 - out_question_multi_intent_accuracy: 0.6109 - out_question_not_really_a_question_accuracy: 0.9896 - out_question_opinion_seeking_accuracy: 0.4113 - out_question_type_choice_accuracy: 0.6394 - out_question_type_compare_accuracy: 0.9340 - out_question_type_consequence_accuracy: 0.9795 - out_question_type_definition_accuracy: 0.9448 - out_question_type_entity_accuracy: 0.8887 - out_question_type_instructions_accuracy: 0.6352 - out_question_type_procedure_accuracy: 0.6343 - out_question_type_reason_explanation_accuracy: 0.5354 - out_question_type_spelling_accuracy: 0.9980 - out_question_well_written_accuracy: 0.3054 - out_answer_helpful_accuracy: 0.6043 - out_answer_level_of_information_accuracy: 0.6779 - out_answer_plausible_accuracy: 0.7744 - out_answer_relevance_accuracy: 0.8066 - out_answer_satisfaction_accuracy: 0.2303 - out_answer_type_instructions_accuracy: 0.6180 - out_answer_type_procedure_accuracy: 0.6940 - out_answer_type_reason_explanation_accuracy: 0.5202 - out_answer_well_written_accuracy: 0.4427\n",
      "Epoch 3/4\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 27.2861 - out_question_asker_intent_understanding_loss: 1.2801 - out_question_body_critical_loss: 1.6655 - out_question_conversational_loss: 0.3099 - out_question_expect_short_answer_loss: 1.2606 - out_question_fact_seeking_loss: 0.9731 - out_question_has_commonly_accepted_answer_loss: 0.8593 - out_question_interestingness_others_loss: 1.5758 - out_question_interestingness_self_loss: 1.5169 - out_question_multi_intent_loss: 0.9477 - out_question_not_really_a_question_loss: 0.0593 - out_question_opinion_seeking_loss: 1.2259 - out_question_type_choice_loss: 0.8278 - out_question_type_compare_loss: 0.2219 - out_question_type_consequence_loss: 0.0966 - out_question_type_definition_loss: 0.1548 - out_question_type_entity_loss: 0.3236 - out_question_type_instructions_loss: 0.8579 - out_question_type_procedure_loss: 0.9006 - out_question_type_reason_explanation_loss: 1.0317 - out_question_type_spelling_loss: 0.0114 - out_question_well_written_loss: 1.6346 - out_answer_helpful_loss: 1.0962 - out_answer_level_of_information_loss: 1.0469 - out_answer_plausible_loss: 0.7674 - out_answer_relevance_loss: 0.6504 - out_answer_satisfaction_loss: 1.9477 - out_answer_type_instructions_loss: 0.9218 - out_answer_type_procedure_loss: 0.8008 - out_answer_type_reason_explanation_loss: 1.0762 - out_answer_well_written_loss: 1.2438 - out_question_asker_intent_understanding_accuracy: 0.4822 - out_question_body_critical_accuracy: 0.3598 - out_question_conversational_accuracy: 0.9025 - out_question_expect_short_answer_accuracy: 0.4938 - out_question_fact_seeking_accuracy: 0.6012 - out_question_has_commonly_accepted_answer_accuracy: 0.7213 - out_question_interestingness_others_accuracy: 0.3443 - out_question_interestingness_self_accuracy: 0.4180 - out_question_multi_intent_accuracy: 0.6389 - out_question_not_really_a_question_accuracy: 0.9896 - out_question_opinion_seeking_accuracy: 0.4596 - out_question_type_choice_accuracy: 0.6737 - out_question_type_compare_accuracy: 0.9359 - out_question_type_consequence_accuracy: 0.9797 - out_question_type_definition_accuracy: 0.9499 - out_question_type_entity_accuracy: 0.8966 - out_question_type_instructions_accuracy: 0.6649 - out_question_type_procedure_accuracy: 0.6448 - out_question_type_reason_explanation_accuracy: 0.5747 - out_question_type_spelling_accuracy: 0.9980 - out_question_well_written_accuracy: 0.3457 - out_answer_helpful_accuracy: 0.6144 - out_answer_level_of_information_accuracy: 0.6821 - out_answer_plausible_accuracy: 0.7754 - out_answer_relevance_accuracy: 0.8075 - out_answer_satisfaction_accuracy: 0.2652 - out_answer_type_instructions_accuracy: 0.6466 - out_answer_type_procedure_accuracy: 0.7075 - out_answer_type_reason_explanation_accuracy: 0.5604 - out_answer_well_written_accuracy: 0.4727\n",
      "validation rho: 0.3811\n",
      "5471/5471 [==============================] - 428s 78ms/sample - loss: 27.2889 - out_question_asker_intent_understanding_loss: 1.2801 - out_question_body_critical_loss: 1.6650 - out_question_conversational_loss: 0.3103 - out_question_expect_short_answer_loss: 1.2608 - out_question_fact_seeking_loss: 0.9730 - out_question_has_commonly_accepted_answer_loss: 0.8599 - out_question_interestingness_others_loss: 1.5756 - out_question_interestingness_self_loss: 1.5169 - out_question_multi_intent_loss: 0.9473 - out_question_not_really_a_question_loss: 0.0593 - out_question_opinion_seeking_loss: 1.2258 - out_question_type_choice_loss: 0.8282 - out_question_type_compare_loss: 0.2224 - out_question_type_consequence_loss: 0.0973 - out_question_type_definition_loss: 0.1546 - out_question_type_entity_loss: 0.3232 - out_question_type_instructions_loss: 0.8576 - out_question_type_procedure_loss: 0.9004 - out_question_type_reason_explanation_loss: 1.0316 - out_question_type_spelling_loss: 0.0114 - out_question_well_written_loss: 1.6336 - out_answer_helpful_loss: 1.0973 - out_answer_level_of_information_loss: 1.0474 - out_answer_plausible_loss: 0.7684 - out_answer_relevance_loss: 0.6521 - out_answer_satisfaction_loss: 1.9475 - out_answer_type_instructions_loss: 0.9212 - out_answer_type_procedure_loss: 0.8011 - out_answer_type_reason_explanation_loss: 1.0761 - out_answer_well_written_loss: 1.2441 - out_question_asker_intent_understanding_accuracy: 0.4820 - out_question_body_critical_accuracy: 0.3599 - out_question_conversational_accuracy: 0.9022 - out_question_expect_short_answer_accuracy: 0.4937 - out_question_fact_seeking_accuracy: 0.6012 - out_question_has_commonly_accepted_answer_accuracy: 0.7213 - out_question_interestingness_others_accuracy: 0.3442 - out_question_interestingness_self_accuracy: 0.4178 - out_question_multi_intent_accuracy: 0.6390 - out_question_not_really_a_question_accuracy: 0.9896 - out_question_opinion_seeking_accuracy: 0.4597 - out_question_type_choice_accuracy: 0.6737 - out_question_type_compare_accuracy: 0.9358 - out_question_type_consequence_accuracy: 0.9795 - out_question_type_definition_accuracy: 0.9499 - out_question_type_entity_accuracy: 0.8967 - out_question_type_instructions_accuracy: 0.6650 - out_question_type_procedure_accuracy: 0.6449 - out_question_type_reason_explanation_accuracy: 0.5747 - out_question_type_spelling_accuracy: 0.9980 - out_question_well_written_accuracy: 0.3462 - out_answer_helpful_accuracy: 0.6138 - out_answer_level_of_information_accuracy: 0.6820 - out_answer_plausible_accuracy: 0.7750 - out_answer_relevance_accuracy: 0.8068 - out_answer_satisfaction_accuracy: 0.2652 - out_answer_type_instructions_accuracy: 0.6469 - out_answer_type_procedure_accuracy: 0.7075 - out_answer_type_reason_explanation_accuracy: 0.5606 - out_answer_well_written_accuracy: 0.4727\n",
      "Epoch 4/4\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 24.7456 - out_question_asker_intent_understanding_loss: 1.1952 - out_question_body_critical_loss: 1.5349 - out_question_conversational_loss: 0.2804 - out_question_expect_short_answer_loss: 1.1666 - out_question_fact_seeking_loss: 0.8760 - out_question_has_commonly_accepted_answer_loss: 0.7816 - out_question_interestingness_others_loss: 1.4663 - out_question_interestingness_self_loss: 1.3977 - out_question_multi_intent_loss: 0.8542 - out_question_not_really_a_question_loss: 0.0534 - out_question_opinion_seeking_loss: 1.1160 - out_question_type_choice_loss: 0.7393 - out_question_type_compare_loss: 0.1905 - out_question_type_consequence_loss: 0.0866 - out_question_type_definition_loss: 0.1352 - out_question_type_entity_loss: 0.2747 - out_question_type_instructions_loss: 0.7734 - out_question_type_procedure_loss: 0.8250 - out_question_type_reason_explanation_loss: 0.9205 - out_question_type_spelling_loss: 0.0080 - out_question_well_written_loss: 1.4931 - out_answer_helpful_loss: 0.9688 - out_answer_level_of_information_loss: 0.9266 - out_answer_plausible_loss: 0.6736 - out_answer_relevance_loss: 0.5711 - out_answer_satisfaction_loss: 1.7879 - out_answer_type_instructions_loss: 0.8134 - out_answer_type_procedure_loss: 0.7412 - out_answer_type_reason_explanation_loss: 0.9567 - out_answer_well_written_loss: 1.1378 - out_question_asker_intent_understanding_accuracy: 0.5190 - out_question_body_critical_accuracy: 0.4131 - out_question_conversational_accuracy: 0.9067 - out_question_expect_short_answer_accuracy: 0.5368 - out_question_fact_seeking_accuracy: 0.6358 - out_question_has_commonly_accepted_answer_accuracy: 0.7341 - out_question_interestingness_others_accuracy: 0.3937 - out_question_interestingness_self_accuracy: 0.4705 - out_question_multi_intent_accuracy: 0.6669 - out_question_not_really_a_question_accuracy: 0.9896 - out_question_opinion_seeking_accuracy: 0.5174 - out_question_type_choice_accuracy: 0.7112 - out_question_type_compare_accuracy: 0.9414 - out_question_type_consequence_accuracy: 0.9793 - out_question_type_definition_accuracy: 0.9566 - out_question_type_entity_accuracy: 0.9078 - out_question_type_instructions_accuracy: 0.6878 - out_question_type_procedure_accuracy: 0.6654 - out_question_type_reason_explanation_accuracy: 0.6133 - out_question_type_spelling_accuracy: 0.9982 - out_question_well_written_accuracy: 0.4112 - out_answer_helpful_accuracy: 0.6373 - out_answer_level_of_information_accuracy: 0.7048 - out_answer_plausible_accuracy: 0.7804 - out_answer_relevance_accuracy: 0.8131 - out_answer_satisfaction_accuracy: 0.3276 - out_answer_type_instructions_accuracy: 0.6788 - out_answer_type_procedure_accuracy: 0.7194 - out_answer_type_reason_explanation_accuracy: 0.6038 - out_answer_well_written_accuracy: 0.5221\n",
      "validation rho: 0.3702\n",
      "5471/5471 [==============================] - 427s 78ms/sample - loss: 24.7477 - out_question_asker_intent_understanding_loss: 1.1945 - out_question_body_critical_loss: 1.5345 - out_question_conversational_loss: 0.2805 - out_question_expect_short_answer_loss: 1.1677 - out_question_fact_seeking_loss: 0.8764 - out_question_has_commonly_accepted_answer_loss: 0.7811 - out_question_interestingness_others_loss: 1.4666 - out_question_interestingness_self_loss: 1.3990 - out_question_multi_intent_loss: 0.8540 - out_question_not_really_a_question_loss: 0.0533 - out_question_opinion_seeking_loss: 1.1165 - out_question_type_choice_loss: 0.7389 - out_question_type_compare_loss: 0.1903 - out_question_type_consequence_loss: 0.0866 - out_question_type_definition_loss: 0.1350 - out_question_type_entity_loss: 0.2743 - out_question_type_instructions_loss: 0.7744 - out_question_type_procedure_loss: 0.8258 - out_question_type_reason_explanation_loss: 0.9203 - out_question_type_spelling_loss: 0.0080 - out_question_well_written_loss: 1.4937 - out_answer_helpful_loss: 0.9690 - out_answer_level_of_information_loss: 0.9260 - out_answer_plausible_loss: 0.6731 - out_answer_relevance_loss: 0.5704 - out_answer_satisfaction_loss: 1.7881 - out_answer_type_instructions_loss: 0.8135 - out_answer_type_procedure_loss: 0.7410 - out_answer_type_reason_explanation_loss: 0.9566 - out_answer_well_written_loss: 1.1390 - out_question_asker_intent_understanding_accuracy: 0.5195 - out_question_body_critical_accuracy: 0.4133 - out_question_conversational_accuracy: 0.9066 - out_question_expect_short_answer_accuracy: 0.5363 - out_question_fact_seeking_accuracy: 0.6355 - out_question_has_commonly_accepted_answer_accuracy: 0.7342 - out_question_interestingness_others_accuracy: 0.3935 - out_question_interestingness_self_accuracy: 0.4701 - out_question_multi_intent_accuracy: 0.6670 - out_question_not_really_a_question_accuracy: 0.9896 - out_question_opinion_seeking_accuracy: 0.5175 - out_question_type_choice_accuracy: 0.7112 - out_question_type_compare_accuracy: 0.9415 - out_question_type_consequence_accuracy: 0.9793 - out_question_type_definition_accuracy: 0.9567 - out_question_type_entity_accuracy: 0.9079 - out_question_type_instructions_accuracy: 0.6874 - out_question_type_procedure_accuracy: 0.6650 - out_question_type_reason_explanation_accuracy: 0.6134 - out_question_type_spelling_accuracy: 0.9982 - out_question_well_written_accuracy: 0.4111 - out_answer_helpful_accuracy: 0.6374 - out_answer_level_of_information_accuracy: 0.7050 - out_answer_plausible_accuracy: 0.7805 - out_answer_relevance_accuracy: 0.8134 - out_answer_satisfaction_accuracy: 0.3274 - out_answer_type_instructions_accuracy: 0.6787 - out_answer_type_procedure_accuracy: 0.7194 - out_answer_type_reason_explanation_accuracy: 0.6039 - out_answer_well_written_accuracy: 0.5218\n",
      "Train on 5471 samples\n",
      "Epoch 1/4\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 31.4761 - out_question_asker_intent_understanding_loss: 1.4035 - out_question_body_critical_loss: 1.9227 - out_question_conversational_loss: 0.4080 - out_question_expect_short_answer_loss: 1.3691 - out_question_fact_seeking_loss: 1.1114 - out_question_has_commonly_accepted_answer_loss: 1.0042 - out_question_interestingness_others_loss: 1.7021 - out_question_interestingness_self_loss: 1.6904 - out_question_multi_intent_loss: 1.1191 - out_question_not_really_a_question_loss: 0.0843 - out_question_opinion_seeking_loss: 1.4324 - out_question_type_choice_loss: 1.1079 - out_question_type_compare_loss: 0.3087 - out_question_type_consequence_loss: 0.1344 - out_question_type_definition_loss: 0.2316 - out_question_type_entity_loss: 0.4678 - out_question_type_instructions_loss: 1.1125 - out_question_type_procedure_loss: 0.9909 - out_question_type_reason_explanation_loss: 1.2730 - out_question_type_spelling_loss: 0.0282 - out_question_well_written_loss: 1.8295 - out_answer_helpful_loss: 1.2088 - out_answer_level_of_information_loss: 1.2219 - out_answer_plausible_loss: 0.8360 - out_answer_relevance_loss: 0.7255 - out_answer_satisfaction_loss: 2.1163 - out_answer_type_instructions_loss: 1.1233 - out_answer_type_procedure_loss: 0.8809 - out_answer_type_reason_explanation_loss: 1.2958 - out_answer_well_written_loss: 1.3358 - out_question_asker_intent_understanding_accuracy: 0.4515 - out_question_body_critical_accuracy: 0.2498 - out_question_conversational_accuracy: 0.8874 - out_question_expect_short_answer_accuracy: 0.4700 - out_question_fact_seeking_accuracy: 0.5673 - out_question_has_commonly_accepted_answer_accuracy: 0.6753 - out_question_interestingness_others_accuracy: 0.2994 - out_question_interestingness_self_accuracy: 0.3543 - out_question_multi_intent_accuracy: 0.5921 - out_question_not_really_a_question_accuracy: 0.9855 - out_question_opinion_seeking_accuracy: 0.3421 - out_question_type_choice_accuracy: 0.5824 - out_question_type_compare_accuracy: 0.9303 - out_question_type_consequence_accuracy: 0.9740 - out_question_type_definition_accuracy: 0.9416 - out_question_type_entity_accuracy: 0.8788 - out_question_type_instructions_accuracy: 0.5741 - out_question_type_procedure_accuracy: 0.6411 - out_question_type_reason_explanation_accuracy: 0.4592 - out_question_type_spelling_accuracy: 0.9936 - out_question_well_written_accuracy: 0.2641 - out_answer_helpful_accuracy: 0.6051 - out_answer_level_of_information_accuracy: 0.6753 - out_answer_plausible_accuracy: 0.7734 - out_answer_relevance_accuracy: 0.8100 - out_answer_satisfaction_accuracy: 0.1997 - out_answer_type_instructions_accuracy: 0.5725 - out_answer_type_procedure_accuracy: 0.6934 - out_answer_type_reason_explanation_accuracy: 0.4735 - out_answer_well_written_accuracy: 0.4061\n",
      "validation rho: 0.3427\n",
      "5471/5471 [==============================] - 460s 84ms/sample - loss: 31.4731 - out_question_asker_intent_understanding_loss: 1.4039 - out_question_body_critical_loss: 1.9218 - out_question_conversational_loss: 0.4078 - out_question_expect_short_answer_loss: 1.3688 - out_question_fact_seeking_loss: 1.1115 - out_question_has_commonly_accepted_answer_loss: 1.0032 - out_question_interestingness_others_loss: 1.7020 - out_question_interestingness_self_loss: 1.6902 - out_question_multi_intent_loss: 1.1193 - out_question_not_really_a_question_loss: 0.0842 - out_question_opinion_seeking_loss: 1.4325 - out_question_type_choice_loss: 1.1073 - out_question_type_compare_loss: 0.3090 - out_question_type_consequence_loss: 0.1343 - out_question_type_definition_loss: 0.2313 - out_question_type_entity_loss: 0.4677 - out_question_type_instructions_loss: 1.1119 - out_question_type_procedure_loss: 0.9906 - out_question_type_reason_explanation_loss: 1.2732 - out_question_type_spelling_loss: 0.0282 - out_question_well_written_loss: 1.8298 - out_answer_helpful_loss: 1.2088 - out_answer_level_of_information_loss: 1.2215 - out_answer_plausible_loss: 0.8360 - out_answer_relevance_loss: 0.7261 - out_answer_satisfaction_loss: 2.1162 - out_answer_type_instructions_loss: 1.1235 - out_answer_type_procedure_loss: 0.8806 - out_answer_type_reason_explanation_loss: 1.2951 - out_answer_well_written_loss: 1.3364 - out_question_asker_intent_understanding_accuracy: 0.4513 - out_question_body_critical_accuracy: 0.2502 - out_question_conversational_accuracy: 0.8874 - out_question_expect_short_answer_accuracy: 0.4699 - out_question_fact_seeking_accuracy: 0.5672 - out_question_has_commonly_accepted_answer_accuracy: 0.6757 - out_question_interestingness_others_accuracy: 0.2996 - out_question_interestingness_self_accuracy: 0.3544 - out_question_multi_intent_accuracy: 0.5922 - out_question_not_really_a_question_accuracy: 0.9856 - out_question_opinion_seeking_accuracy: 0.3418 - out_question_type_choice_accuracy: 0.5825 - out_question_type_compare_accuracy: 0.9302 - out_question_type_consequence_accuracy: 0.9740 - out_question_type_definition_accuracy: 0.9417 - out_question_type_entity_accuracy: 0.8788 - out_question_type_instructions_accuracy: 0.5741 - out_question_type_procedure_accuracy: 0.6412 - out_question_type_reason_explanation_accuracy: 0.4590 - out_question_type_spelling_accuracy: 0.9936 - out_question_well_written_accuracy: 0.2639 - out_answer_helpful_accuracy: 0.6050 - out_answer_level_of_information_accuracy: 0.6754 - out_answer_plausible_accuracy: 0.7735 - out_answer_relevance_accuracy: 0.8099 - out_answer_satisfaction_accuracy: 0.1996 - out_answer_type_instructions_accuracy: 0.5725 - out_answer_type_procedure_accuracy: 0.6935 - out_answer_type_reason_explanation_accuracy: 0.4740 - out_answer_well_written_accuracy: 0.4061\n",
      "Epoch 2/4\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 28.9369 - out_question_asker_intent_understanding_loss: 1.3403 - out_question_body_critical_loss: 1.7742 - out_question_conversational_loss: 0.3466 - out_question_expect_short_answer_loss: 1.3112 - out_question_fact_seeking_loss: 1.0259 - out_question_has_commonly_accepted_answer_loss: 0.9183 - out_question_interestingness_others_loss: 1.6394 - out_question_interestingness_self_loss: 1.6026 - out_question_multi_intent_loss: 1.0107 - out_question_not_really_a_question_loss: 0.0684 - out_question_opinion_seeking_loss: 1.3111 - out_question_type_choice_loss: 0.8895 - out_question_type_compare_loss: 0.2527 - out_question_type_consequence_loss: 0.1101 - out_question_type_definition_loss: 0.1706 - out_question_type_entity_loss: 0.3812 - out_question_type_instructions_loss: 0.9410 - out_question_type_procedure_loss: 0.9387 - out_question_type_reason_explanation_loss: 1.0968 - out_question_type_spelling_loss: 0.0134 - out_question_well_written_loss: 1.7223 - out_answer_helpful_loss: 1.1680 - out_answer_level_of_information_loss: 1.1324 - out_answer_plausible_loss: 0.8082 - out_answer_relevance_loss: 0.6808 - out_answer_satisfaction_loss: 2.0339 - out_answer_type_instructions_loss: 0.9897 - out_answer_type_procedure_loss: 0.8361 - out_answer_type_reason_explanation_loss: 1.1454 - out_answer_well_written_loss: 1.2775 - out_question_asker_intent_understanding_accuracy: 0.4669 - out_question_body_critical_accuracy: 0.3126 - out_question_conversational_accuracy: 0.8885 - out_question_expect_short_answer_accuracy: 0.4799 - out_question_fact_seeking_accuracy: 0.5899 - out_question_has_commonly_accepted_answer_accuracy: 0.7068 - out_question_interestingness_others_accuracy: 0.3245 - out_question_interestingness_self_accuracy: 0.3827 - out_question_multi_intent_accuracy: 0.6144 - out_question_not_really_a_question_accuracy: 0.9887 - out_question_opinion_seeking_accuracy: 0.4158 - out_question_type_choice_accuracy: 0.6565 - out_question_type_compare_accuracy: 0.9337 - out_question_type_consequence_accuracy: 0.9780 - out_question_type_definition_accuracy: 0.9436 - out_question_type_entity_accuracy: 0.8831 - out_question_type_instructions_accuracy: 0.6354 - out_question_type_procedure_accuracy: 0.6402 - out_question_type_reason_explanation_accuracy: 0.5450 - out_question_type_spelling_accuracy: 0.9982 - out_question_well_written_accuracy: 0.3034 - out_answer_helpful_accuracy: 0.6056 - out_answer_level_of_information_accuracy: 0.6790 - out_answer_plausible_accuracy: 0.7745 - out_answer_relevance_accuracy: 0.8115 - out_answer_satisfaction_accuracy: 0.2423 - out_answer_type_instructions_accuracy: 0.6162 - out_answer_type_procedure_accuracy: 0.6977 - out_answer_type_reason_explanation_accuracy: 0.5412 - out_answer_well_written_accuracy: 0.4422\n",
      "validation rho: 0.3542\n",
      "5471/5471 [==============================] - 427s 78ms/sample - loss: 28.9345 - out_question_asker_intent_understanding_loss: 1.3408 - out_question_body_critical_loss: 1.7751 - out_question_conversational_loss: 0.3462 - out_question_expect_short_answer_loss: 1.3112 - out_question_fact_seeking_loss: 1.0251 - out_question_has_commonly_accepted_answer_loss: 0.9174 - out_question_interestingness_others_loss: 1.6399 - out_question_interestingness_self_loss: 1.6033 - out_question_multi_intent_loss: 1.0105 - out_question_not_really_a_question_loss: 0.0684 - out_question_opinion_seeking_loss: 1.3111 - out_question_type_choice_loss: 0.8893 - out_question_type_compare_loss: 0.2524 - out_question_type_consequence_loss: 0.1100 - out_question_type_definition_loss: 0.1706 - out_question_type_entity_loss: 0.3807 - out_question_type_instructions_loss: 0.9408 - out_question_type_procedure_loss: 0.9393 - out_question_type_reason_explanation_loss: 1.0962 - out_question_type_spelling_loss: 0.0133 - out_question_well_written_loss: 1.7222 - out_answer_helpful_loss: 1.1680 - out_answer_level_of_information_loss: 1.1318 - out_answer_plausible_loss: 0.8074 - out_answer_relevance_loss: 0.6815 - out_answer_satisfaction_loss: 2.0336 - out_answer_type_instructions_loss: 0.9892 - out_answer_type_procedure_loss: 0.8365 - out_answer_type_reason_explanation_loss: 1.1451 - out_answer_well_written_loss: 1.2771 - out_question_asker_intent_understanding_accuracy: 0.4665 - out_question_body_critical_accuracy: 0.3122 - out_question_conversational_accuracy: 0.8887 - out_question_expect_short_answer_accuracy: 0.4798 - out_question_fact_seeking_accuracy: 0.5904 - out_question_has_commonly_accepted_answer_accuracy: 0.7072 - out_question_interestingness_others_accuracy: 0.3241 - out_question_interestingness_self_accuracy: 0.3827 - out_question_multi_intent_accuracy: 0.6145 - out_question_not_really_a_question_accuracy: 0.9887 - out_question_opinion_seeking_accuracy: 0.4156 - out_question_type_choice_accuracy: 0.6566 - out_question_type_compare_accuracy: 0.9338 - out_question_type_consequence_accuracy: 0.9781 - out_question_type_definition_accuracy: 0.9437 - out_question_type_entity_accuracy: 0.8832 - out_question_type_instructions_accuracy: 0.6355 - out_question_type_procedure_accuracy: 0.6401 - out_question_type_reason_explanation_accuracy: 0.5452 - out_question_type_spelling_accuracy: 0.9982 - out_question_well_written_accuracy: 0.3032 - out_answer_helpful_accuracy: 0.6056 - out_answer_level_of_information_accuracy: 0.6790 - out_answer_plausible_accuracy: 0.7748 - out_answer_relevance_accuracy: 0.8112 - out_answer_satisfaction_accuracy: 0.2426 - out_answer_type_instructions_accuracy: 0.6163 - out_answer_type_procedure_accuracy: 0.6975 - out_answer_type_reason_explanation_accuracy: 0.5412 - out_answer_well_written_accuracy: 0.4423\n",
      "Epoch 3/4\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 27.1214 - out_question_asker_intent_understanding_loss: 1.2790 - out_question_body_critical_loss: 1.6690 - out_question_conversational_loss: 0.3134 - out_question_expect_short_answer_loss: 1.2543 - out_question_fact_seeking_loss: 0.9588 - out_question_has_commonly_accepted_answer_loss: 0.8441 - out_question_interestingness_others_loss: 1.5823 - out_question_interestingness_self_loss: 1.5277 - out_question_multi_intent_loss: 0.9267 - out_question_not_really_a_question_loss: 0.0640 - out_question_opinion_seeking_loss: 1.2326 - out_question_type_choice_loss: 0.8190 - out_question_type_compare_loss: 0.2184 - out_question_type_consequence_loss: 0.0992 - out_question_type_definition_loss: 0.1495 - out_question_type_entity_loss: 0.3286 - out_question_type_instructions_loss: 0.8651 - out_question_type_procedure_loss: 0.8899 - out_question_type_reason_explanation_loss: 1.0169 - out_question_type_spelling_loss: 0.0111 - out_question_well_written_loss: 1.6286 - out_answer_helpful_loss: 1.0871 - out_answer_level_of_information_loss: 1.0287 - out_answer_plausible_loss: 0.7640 - out_answer_relevance_loss: 0.6371 - out_answer_satisfaction_loss: 1.9300 - out_answer_type_instructions_loss: 0.9090 - out_answer_type_procedure_loss: 0.7971 - out_answer_type_reason_explanation_loss: 1.0520 - out_answer_well_written_loss: 1.2379 - out_question_asker_intent_understanding_accuracy: 0.4885 - out_question_body_critical_accuracy: 0.3605 - out_question_conversational_accuracy: 0.8933 - out_question_expect_short_answer_accuracy: 0.5004 - out_question_fact_seeking_accuracy: 0.6061 - out_question_has_commonly_accepted_answer_accuracy: 0.7214 - out_question_interestingness_others_accuracy: 0.3437 - out_question_interestingness_self_accuracy: 0.4209 - out_question_multi_intent_accuracy: 0.6365 - out_question_not_really_a_question_accuracy: 0.9887 - out_question_opinion_seeking_accuracy: 0.4685 - out_question_type_choice_accuracy: 0.6748 - out_question_type_compare_accuracy: 0.9341 - out_question_type_consequence_accuracy: 0.9782 - out_question_type_definition_accuracy: 0.9506 - out_question_type_entity_accuracy: 0.8940 - out_question_type_instructions_accuracy: 0.6545 - out_question_type_procedure_accuracy: 0.6519 - out_question_type_reason_explanation_accuracy: 0.5814 - out_question_type_spelling_accuracy: 0.9982 - out_question_well_written_accuracy: 0.3518 - out_answer_helpful_accuracy: 0.6127 - out_answer_level_of_information_accuracy: 0.6869 - out_answer_plausible_accuracy: 0.7751 - out_answer_relevance_accuracy: 0.8117 - out_answer_satisfaction_accuracy: 0.2727 - out_answer_type_instructions_accuracy: 0.6429 - out_answer_type_procedure_accuracy: 0.7042 - out_answer_type_reason_explanation_accuracy: 0.5694 - out_answer_well_written_accuracy: 0.4828\n",
      "validation rho: 0.349\n",
      "5471/5471 [==============================] - 426s 78ms/sample - loss: 27.1170 - out_question_asker_intent_understanding_loss: 1.2790 - out_question_body_critical_loss: 1.6689 - out_question_conversational_loss: 0.3130 - out_question_expect_short_answer_loss: 1.2537 - out_question_fact_seeking_loss: 0.9588 - out_question_has_commonly_accepted_answer_loss: 0.8436 - out_question_interestingness_others_loss: 1.5817 - out_question_interestingness_self_loss: 1.5275 - out_question_multi_intent_loss: 0.9260 - out_question_not_really_a_question_loss: 0.0639 - out_question_opinion_seeking_loss: 1.2327 - out_question_type_choice_loss: 0.8187 - out_question_type_compare_loss: 0.2181 - out_question_type_consequence_loss: 0.0991 - out_question_type_definition_loss: 0.1493 - out_question_type_entity_loss: 0.3281 - out_question_type_instructions_loss: 0.8652 - out_question_type_procedure_loss: 0.8902 - out_question_type_reason_explanation_loss: 1.0168 - out_question_type_spelling_loss: 0.0111 - out_question_well_written_loss: 1.6291 - out_answer_helpful_loss: 1.0867 - out_answer_level_of_information_loss: 1.0282 - out_answer_plausible_loss: 0.7632 - out_answer_relevance_loss: 0.6373 - out_answer_satisfaction_loss: 1.9292 - out_answer_type_instructions_loss: 0.9092 - out_answer_type_procedure_loss: 0.7982 - out_answer_type_reason_explanation_loss: 1.0517 - out_answer_well_written_loss: 1.2385 - out_question_asker_intent_understanding_accuracy: 0.4886 - out_question_body_critical_accuracy: 0.3603 - out_question_conversational_accuracy: 0.8934 - out_question_expect_short_answer_accuracy: 0.5005 - out_question_fact_seeking_accuracy: 0.6061 - out_question_has_commonly_accepted_answer_accuracy: 0.7216 - out_question_interestingness_others_accuracy: 0.3440 - out_question_interestingness_self_accuracy: 0.4206 - out_question_multi_intent_accuracy: 0.6368 - out_question_not_really_a_question_accuracy: 0.9887 - out_question_opinion_seeking_accuracy: 0.4681 - out_question_type_choice_accuracy: 0.6750 - out_question_type_compare_accuracy: 0.9342 - out_question_type_consequence_accuracy: 0.9782 - out_question_type_definition_accuracy: 0.9506 - out_question_type_entity_accuracy: 0.8942 - out_question_type_instructions_accuracy: 0.6545 - out_question_type_procedure_accuracy: 0.6518 - out_question_type_reason_explanation_accuracy: 0.5814 - out_question_type_spelling_accuracy: 0.9982 - out_question_well_written_accuracy: 0.3517 - out_answer_helpful_accuracy: 0.6131 - out_answer_level_of_information_accuracy: 0.6871 - out_answer_plausible_accuracy: 0.7754 - out_answer_relevance_accuracy: 0.8116 - out_answer_satisfaction_accuracy: 0.2729 - out_answer_type_instructions_accuracy: 0.6428 - out_answer_type_procedure_accuracy: 0.7039 - out_answer_type_reason_explanation_accuracy: 0.5694 - out_answer_well_written_accuracy: 0.4827\n",
      "Epoch 4/4\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 24.6255 - out_question_asker_intent_understanding_loss: 1.1918 - out_question_body_critical_loss: 1.5400 - out_question_conversational_loss: 0.2755 - out_question_expect_short_answer_loss: 1.1677 - out_question_fact_seeking_loss: 0.8740 - out_question_has_commonly_accepted_answer_loss: 0.7744 - out_question_interestingness_others_loss: 1.4753 - out_question_interestingness_self_loss: 1.4186 - out_question_multi_intent_loss: 0.8252 - out_question_not_really_a_question_loss: 0.0591 - out_question_opinion_seeking_loss: 1.1112 - out_question_type_choice_loss: 0.7291 - out_question_type_compare_loss: 0.1912 - out_question_type_consequence_loss: 0.0852 - out_question_type_definition_loss: 0.1299 - out_question_type_entity_loss: 0.2781 - out_question_type_instructions_loss: 0.7836 - out_question_type_procedure_loss: 0.8287 - out_question_type_reason_explanation_loss: 0.9050 - out_question_type_spelling_loss: 0.0088 - out_question_well_written_loss: 1.4928 - out_answer_helpful_loss: 0.9638 - out_answer_level_of_information_loss: 0.8994 - out_answer_plausible_loss: 0.6723 - out_answer_relevance_loss: 0.5630 - out_answer_satisfaction_loss: 1.7730 - out_answer_type_instructions_loss: 0.8036 - out_answer_type_procedure_loss: 0.7399 - out_answer_type_reason_explanation_loss: 0.9322 - out_answer_well_written_loss: 1.1328 - out_question_asker_intent_understanding_accuracy: 0.5258 - out_question_body_critical_accuracy: 0.4114 - out_question_conversational_accuracy: 0.9039 - out_question_expect_short_answer_accuracy: 0.5339 - out_question_fact_seeking_accuracy: 0.6363 - out_question_has_commonly_accepted_answer_accuracy: 0.7361 - out_question_interestingness_others_accuracy: 0.3939 - out_question_interestingness_self_accuracy: 0.4563 - out_question_multi_intent_accuracy: 0.6770 - out_question_not_really_a_question_accuracy: 0.9887 - out_question_opinion_seeking_accuracy: 0.5326 - out_question_type_choice_accuracy: 0.7101 - out_question_type_compare_accuracy: 0.9423 - out_question_type_consequence_accuracy: 0.9788 - out_question_type_definition_accuracy: 0.9583 - out_question_type_entity_accuracy: 0.9067 - out_question_type_instructions_accuracy: 0.6889 - out_question_type_procedure_accuracy: 0.6695 - out_question_type_reason_explanation_accuracy: 0.6274 - out_question_type_spelling_accuracy: 0.9982 - out_question_well_written_accuracy: 0.4100 - out_answer_helpful_accuracy: 0.6407 - out_answer_level_of_information_accuracy: 0.7097 - out_answer_plausible_accuracy: 0.7829 - out_answer_relevance_accuracy: 0.8164 - out_answer_satisfaction_accuracy: 0.3366 - out_answer_type_instructions_accuracy: 0.6803 - out_answer_type_procedure_accuracy: 0.7158 - out_answer_type_reason_explanation_accuracy: 0.6191 - out_answer_well_written_accuracy: 0.5434\n",
      "validation rho: 0.3676\n",
      "5471/5471 [==============================] - 427s 78ms/sample - loss: 24.6289 - out_question_asker_intent_understanding_loss: 1.1917 - out_question_body_critical_loss: 1.5407 - out_question_conversational_loss: 0.2751 - out_question_expect_short_answer_loss: 1.1675 - out_question_fact_seeking_loss: 0.8734 - out_question_has_commonly_accepted_answer_loss: 0.7747 - out_question_interestingness_others_loss: 1.4758 - out_question_interestingness_self_loss: 1.4187 - out_question_multi_intent_loss: 0.8257 - out_question_not_really_a_question_loss: 0.0590 - out_question_opinion_seeking_loss: 1.1115 - out_question_type_choice_loss: 0.7297 - out_question_type_compare_loss: 0.1910 - out_question_type_consequence_loss: 0.0851 - out_question_type_definition_loss: 0.1302 - out_question_type_entity_loss: 0.2780 - out_question_type_instructions_loss: 0.7835 - out_question_type_procedure_loss: 0.8289 - out_question_type_reason_explanation_loss: 0.9055 - out_question_type_spelling_loss: 0.0088 - out_question_well_written_loss: 1.4927 - out_answer_helpful_loss: 0.9645 - out_answer_level_of_information_loss: 0.9001 - out_answer_plausible_loss: 0.6724 - out_answer_relevance_loss: 0.5629 - out_answer_satisfaction_loss: 1.7732 - out_answer_type_instructions_loss: 0.8032 - out_answer_type_procedure_loss: 0.7398 - out_answer_type_reason_explanation_loss: 0.9325 - out_answer_well_written_loss: 1.1334 - out_question_asker_intent_understanding_accuracy: 0.5259 - out_question_body_critical_accuracy: 0.4113 - out_question_conversational_accuracy: 0.9040 - out_question_expect_short_answer_accuracy: 0.5339 - out_question_fact_seeking_accuracy: 0.6366 - out_question_has_commonly_accepted_answer_accuracy: 0.7359 - out_question_interestingness_others_accuracy: 0.3937 - out_question_interestingness_self_accuracy: 0.4562 - out_question_multi_intent_accuracy: 0.6767 - out_question_not_really_a_question_accuracy: 0.9887 - out_question_opinion_seeking_accuracy: 0.5324 - out_question_type_choice_accuracy: 0.7097 - out_question_type_compare_accuracy: 0.9424 - out_question_type_consequence_accuracy: 0.9788 - out_question_type_definition_accuracy: 0.9580 - out_question_type_entity_accuracy: 0.9068 - out_question_type_instructions_accuracy: 0.6889 - out_question_type_procedure_accuracy: 0.6693 - out_question_type_reason_explanation_accuracy: 0.6268 - out_question_type_spelling_accuracy: 0.9982 - out_question_well_written_accuracy: 0.4098 - out_answer_helpful_accuracy: 0.6407 - out_answer_level_of_information_accuracy: 0.7096 - out_answer_plausible_accuracy: 0.7830 - out_answer_relevance_accuracy: 0.8165 - out_answer_satisfaction_accuracy: 0.3365 - out_answer_type_instructions_accuracy: 0.6805 - out_answer_type_procedure_accuracy: 0.7160 - out_answer_type_reason_explanation_accuracy: 0.6193 - out_answer_well_written_accuracy: 0.5432\n",
      "Train on 5471 samples\n",
      "Epoch 1/4\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 31.5704 - out_question_asker_intent_understanding_loss: 1.3837 - out_question_body_critical_loss: 1.9249 - out_question_conversational_loss: 0.4138 - out_question_expect_short_answer_loss: 1.3656 - out_question_fact_seeking_loss: 1.1162 - out_question_has_commonly_accepted_answer_loss: 1.0147 - out_question_interestingness_others_loss: 1.7037 - out_question_interestingness_self_loss: 1.7114 - out_question_multi_intent_loss: 1.1288 - out_question_not_really_a_question_loss: 0.0785 - out_question_opinion_seeking_loss: 1.4184 - out_question_type_choice_loss: 1.1260 - out_question_type_compare_loss: 0.3312 - out_question_type_consequence_loss: 0.1251 - out_question_type_definition_loss: 0.2389 - out_question_type_entity_loss: 0.4748 - out_question_type_instructions_loss: 1.1156 - out_question_type_procedure_loss: 0.9943 - out_question_type_reason_explanation_loss: 1.2918 - out_question_type_spelling_loss: 0.0169 - out_question_well_written_loss: 1.8123 - out_answer_helpful_loss: 1.2201 - out_answer_level_of_information_loss: 1.2097 - out_answer_plausible_loss: 0.8563 - out_answer_relevance_loss: 0.7339 - out_answer_satisfaction_loss: 2.1120 - out_answer_type_instructions_loss: 1.1337 - out_answer_type_procedure_loss: 0.8839 - out_answer_type_reason_explanation_loss: 1.3052 - out_answer_well_written_loss: 1.3287 - out_question_asker_intent_understanding_accuracy: 0.4645 - out_question_body_critical_accuracy: 0.2496 - out_question_conversational_accuracy: 0.8847 - out_question_expect_short_answer_accuracy: 0.4702 - out_question_fact_seeking_accuracy: 0.5648 - out_question_has_commonly_accepted_answer_accuracy: 0.6759 - out_question_interestingness_others_accuracy: 0.3038 - out_question_interestingness_self_accuracy: 0.3424 - out_question_multi_intent_accuracy: 0.5919 - out_question_not_really_a_question_accuracy: 0.9872 - out_question_opinion_seeking_accuracy: 0.3483 - out_question_type_choice_accuracy: 0.5738 - out_question_type_compare_accuracy: 0.9277 - out_question_type_consequence_accuracy: 0.9788 - out_question_type_definition_accuracy: 0.9414 - out_question_type_entity_accuracy: 0.8792 - out_question_type_instructions_accuracy: 0.5747 - out_question_type_procedure_accuracy: 0.6374 - out_question_type_reason_explanation_accuracy: 0.4546 - out_question_type_spelling_accuracy: 0.9980 - out_question_well_written_accuracy: 0.2710 - out_answer_helpful_accuracy: 0.6012 - out_answer_level_of_information_accuracy: 0.6777 - out_answer_plausible_accuracy: 0.7707 - out_answer_relevance_accuracy: 0.8049 - out_answer_satisfaction_accuracy: 0.2128 - out_answer_type_instructions_accuracy: 0.5663 - out_answer_type_procedure_accuracy: 0.6925 - out_answer_type_reason_explanation_accuracy: 0.4607 - out_answer_well_written_accuracy: 0.4171\n",
      "validation rho: 0.3301\n",
      "5471/5471 [==============================] - 461s 84ms/sample - loss: 31.5649 - out_question_asker_intent_understanding_loss: 1.3829 - out_question_body_critical_loss: 1.9245 - out_question_conversational_loss: 0.4135 - out_question_expect_short_answer_loss: 1.3654 - out_question_fact_seeking_loss: 1.1163 - out_question_has_commonly_accepted_answer_loss: 1.0146 - out_question_interestingness_others_loss: 1.7035 - out_question_interestingness_self_loss: 1.7107 - out_question_multi_intent_loss: 1.1288 - out_question_not_really_a_question_loss: 0.0784 - out_question_opinion_seeking_loss: 1.4180 - out_question_type_choice_loss: 1.1266 - out_question_type_compare_loss: 0.3313 - out_question_type_consequence_loss: 0.1250 - out_question_type_definition_loss: 0.2389 - out_question_type_entity_loss: 0.4754 - out_question_type_instructions_loss: 1.1147 - out_question_type_procedure_loss: 0.9934 - out_question_type_reason_explanation_loss: 1.2915 - out_question_type_spelling_loss: 0.0169 - out_question_well_written_loss: 1.8125 - out_answer_helpful_loss: 1.2201 - out_answer_level_of_information_loss: 1.2097 - out_answer_plausible_loss: 0.8555 - out_answer_relevance_loss: 0.7336 - out_answer_satisfaction_loss: 2.1123 - out_answer_type_instructions_loss: 1.1328 - out_answer_type_procedure_loss: 0.8835 - out_answer_type_reason_explanation_loss: 1.3045 - out_answer_well_written_loss: 1.3294 - out_question_asker_intent_understanding_accuracy: 0.4652 - out_question_body_critical_accuracy: 0.2497 - out_question_conversational_accuracy: 0.8848 - out_question_expect_short_answer_accuracy: 0.4699 - out_question_fact_seeking_accuracy: 0.5646 - out_question_has_commonly_accepted_answer_accuracy: 0.6757 - out_question_interestingness_others_accuracy: 0.3038 - out_question_interestingness_self_accuracy: 0.3429 - out_question_multi_intent_accuracy: 0.5918 - out_question_not_really_a_question_accuracy: 0.9872 - out_question_opinion_seeking_accuracy: 0.3484 - out_question_type_choice_accuracy: 0.5736 - out_question_type_compare_accuracy: 0.9276 - out_question_type_consequence_accuracy: 0.9788 - out_question_type_definition_accuracy: 0.9413 - out_question_type_entity_accuracy: 0.8792 - out_question_type_instructions_accuracy: 0.5750 - out_question_type_procedure_accuracy: 0.6379 - out_question_type_reason_explanation_accuracy: 0.4549 - out_question_type_spelling_accuracy: 0.9980 - out_question_well_written_accuracy: 0.2707 - out_answer_helpful_accuracy: 0.6012 - out_answer_level_of_information_accuracy: 0.6776 - out_answer_plausible_accuracy: 0.7710 - out_answer_relevance_accuracy: 0.8050 - out_answer_satisfaction_accuracy: 0.2126 - out_answer_type_instructions_accuracy: 0.5666 - out_answer_type_procedure_accuracy: 0.6927 - out_answer_type_reason_explanation_accuracy: 0.4612 - out_answer_well_written_accuracy: 0.4167\n",
      "Epoch 2/4\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 29.0461 - out_question_asker_intent_understanding_loss: 1.3265 - out_question_body_critical_loss: 1.7661 - out_question_conversational_loss: 0.3574 - out_question_expect_short_answer_loss: 1.3175 - out_question_fact_seeking_loss: 1.0320 - out_question_has_commonly_accepted_answer_loss: 0.9330 - out_question_interestingness_others_loss: 1.6401 - out_question_interestingness_self_loss: 1.6199 - out_question_multi_intent_loss: 1.0137 - out_question_not_really_a_question_loss: 0.0651 - out_question_opinion_seeking_loss: 1.3151 - out_question_type_choice_loss: 0.9038 - out_question_type_compare_loss: 0.2645 - out_question_type_consequence_loss: 0.1067 - out_question_type_definition_loss: 0.1807 - out_question_type_entity_loss: 0.3984 - out_question_type_instructions_loss: 0.9382 - out_question_type_procedure_loss: 0.9326 - out_question_type_reason_explanation_loss: 1.1129 - out_question_type_spelling_loss: 0.0146 - out_question_well_written_loss: 1.7063 - out_answer_helpful_loss: 1.1672 - out_answer_level_of_information_loss: 1.1233 - out_answer_plausible_loss: 0.8089 - out_answer_relevance_loss: 0.6945 - out_answer_satisfaction_loss: 2.0284 - out_answer_type_instructions_loss: 0.9930 - out_answer_type_procedure_loss: 0.8372 - out_answer_type_reason_explanation_loss: 1.1623 - out_answer_well_written_loss: 1.2860 - out_question_asker_intent_understanding_accuracy: 0.4753 - out_question_body_critical_accuracy: 0.3131 - out_question_conversational_accuracy: 0.8874 - out_question_expect_short_answer_accuracy: 0.4848 - out_question_fact_seeking_accuracy: 0.5878 - out_question_has_commonly_accepted_answer_accuracy: 0.7006 - out_question_interestingness_others_accuracy: 0.3294 - out_question_interestingness_self_accuracy: 0.3792 - out_question_multi_intent_accuracy: 0.6137 - out_question_not_really_a_question_accuracy: 0.9892 - out_question_opinion_seeking_accuracy: 0.4070 - out_question_type_choice_accuracy: 0.6572 - out_question_type_compare_accuracy: 0.9295 - out_question_type_consequence_accuracy: 0.9791 - out_question_type_definition_accuracy: 0.9436 - out_question_type_entity_accuracy: 0.8825 - out_question_type_instructions_accuracy: 0.6380 - out_question_type_procedure_accuracy: 0.6459 - out_question_type_reason_explanation_accuracy: 0.5404 - out_question_type_spelling_accuracy: 0.9980 - out_question_well_written_accuracy: 0.3077 - out_answer_helpful_accuracy: 0.6067 - out_answer_level_of_information_accuracy: 0.6805 - out_answer_plausible_accuracy: 0.7749 - out_answer_relevance_accuracy: 0.8069 - out_answer_satisfaction_accuracy: 0.2471 - out_answer_type_instructions_accuracy: 0.6221 - out_answer_type_procedure_accuracy: 0.6958 - out_answer_type_reason_explanation_accuracy: 0.5337 - out_answer_well_written_accuracy: 0.4385\n",
      "validation rho: 0.3492\n",
      "5471/5471 [==============================] - 429s 78ms/sample - loss: 29.0446 - out_question_asker_intent_understanding_loss: 1.3262 - out_question_body_critical_loss: 1.7661 - out_question_conversational_loss: 0.3580 - out_question_expect_short_answer_loss: 1.3177 - out_question_fact_seeking_loss: 1.0315 - out_question_has_commonly_accepted_answer_loss: 0.9343 - out_question_interestingness_others_loss: 1.6412 - out_question_interestingness_self_loss: 1.6211 - out_question_multi_intent_loss: 1.0132 - out_question_not_really_a_question_loss: 0.0651 - out_question_opinion_seeking_loss: 1.3153 - out_question_type_choice_loss: 0.9036 - out_question_type_compare_loss: 0.2642 - out_question_type_consequence_loss: 0.1065 - out_question_type_definition_loss: 0.1805 - out_question_type_entity_loss: 0.3983 - out_question_type_instructions_loss: 0.9377 - out_question_type_procedure_loss: 0.9318 - out_question_type_reason_explanation_loss: 1.1129 - out_question_type_spelling_loss: 0.0146 - out_question_well_written_loss: 1.7060 - out_answer_helpful_loss: 1.1670 - out_answer_level_of_information_loss: 1.1232 - out_answer_plausible_loss: 0.8090 - out_answer_relevance_loss: 0.6939 - out_answer_satisfaction_loss: 2.0281 - out_answer_type_instructions_loss: 0.9929 - out_answer_type_procedure_loss: 0.8368 - out_answer_type_reason_explanation_loss: 1.1618 - out_answer_well_written_loss: 1.2857 - out_question_asker_intent_understanding_accuracy: 0.4756 - out_question_body_critical_accuracy: 0.3129 - out_question_conversational_accuracy: 0.8872 - out_question_expect_short_answer_accuracy: 0.4847 - out_question_fact_seeking_accuracy: 0.5880 - out_question_has_commonly_accepted_answer_accuracy: 0.7001 - out_question_interestingness_others_accuracy: 0.3294 - out_question_interestingness_self_accuracy: 0.3791 - out_question_multi_intent_accuracy: 0.6140 - out_question_not_really_a_question_accuracy: 0.9892 - out_question_opinion_seeking_accuracy: 0.4067 - out_question_type_choice_accuracy: 0.6575 - out_question_type_compare_accuracy: 0.9296 - out_question_type_consequence_accuracy: 0.9792 - out_question_type_definition_accuracy: 0.9437 - out_question_type_entity_accuracy: 0.8827 - out_question_type_instructions_accuracy: 0.6383 - out_question_type_procedure_accuracy: 0.6461 - out_question_type_reason_explanation_accuracy: 0.5405 - out_question_type_spelling_accuracy: 0.9980 - out_question_well_written_accuracy: 0.3076 - out_answer_helpful_accuracy: 0.6068 - out_answer_level_of_information_accuracy: 0.6805 - out_answer_plausible_accuracy: 0.7748 - out_answer_relevance_accuracy: 0.8072 - out_answer_satisfaction_accuracy: 0.2473 - out_answer_type_instructions_accuracy: 0.6220 - out_answer_type_procedure_accuracy: 0.6960 - out_answer_type_reason_explanation_accuracy: 0.5339 - out_answer_well_written_accuracy: 0.4385\n",
      "Epoch 3/4\n",
      "5464/5471 [============================>.] - ETA: 0s - loss: 27.2746 - out_question_asker_intent_understanding_loss: 1.2759 - out_question_body_critical_loss: 1.6623 - out_question_conversational_loss: 0.3204 - out_question_expect_short_answer_loss: 1.2584 - out_question_fact_seeking_loss: 0.9677 - out_question_has_commonly_accepted_answer_loss: 0.8793 - out_question_interestingness_others_loss: 1.5890 - out_question_interestingness_self_loss: 1.5498 - out_question_multi_intent_loss: 0.9321 - out_question_not_really_a_question_loss: 0.0618 - out_question_opinion_seeking_loss: 1.2214 - out_question_type_choice_loss: 0.8267 - out_question_type_compare_loss: 0.2268 - out_question_type_consequence_loss: 0.0948 - out_question_type_definition_loss: 0.1569 - out_question_type_entity_loss: 0.3440 - out_question_type_instructions_loss: 0.8554 - out_question_type_procedure_loss: 0.8926 - out_question_type_reason_explanation_loss: 1.0210 - out_question_type_spelling_loss: 0.0116 - out_question_well_written_loss: 1.6345 - out_answer_helpful_loss: 1.0980 - out_answer_level_of_information_loss: 1.0356 - out_answer_plausible_loss: 0.7637 - out_answer_relevance_loss: 0.6524 - out_answer_satisfaction_loss: 1.9305 - out_answer_type_instructions_loss: 0.9058 - out_answer_type_procedure_loss: 0.7996 - out_answer_type_reason_explanation_loss: 1.0766 - out_answer_well_written_loss: 1.2298 - out_question_asker_intent_understanding_accuracy: 0.4945 - out_question_body_critical_accuracy: 0.3523 - out_question_conversational_accuracy: 0.8946 - out_question_expect_short_answer_accuracy: 0.5024 - out_question_fact_seeking_accuracy: 0.6040 - out_question_has_commonly_accepted_answer_accuracy: 0.7158 - out_question_interestingness_others_accuracy: 0.3366 - out_question_interestingness_self_accuracy: 0.4068 - out_question_multi_intent_accuracy: 0.6389 - out_question_not_really_a_question_accuracy: 0.9892 - out_question_opinion_seeking_accuracy: 0.4559 - out_question_type_choice_accuracy: 0.6843 - out_question_type_compare_accuracy: 0.9314 - out_question_type_consequence_accuracy: 0.9791 - out_question_type_definition_accuracy: 0.9466 - out_question_type_entity_accuracy: 0.8902 - out_question_type_instructions_accuracy: 0.6700 - out_question_type_procedure_accuracy: 0.6517 - out_question_type_reason_explanation_accuracy: 0.5822 - out_question_type_spelling_accuracy: 0.9980 - out_question_well_written_accuracy: 0.3512 - out_answer_helpful_accuracy: 0.6135 - out_answer_level_of_information_accuracy: 0.6817 - out_answer_plausible_accuracy: 0.7751 - out_answer_relevance_accuracy: 0.8091 - out_answer_satisfaction_accuracy: 0.2795 - out_answer_type_instructions_accuracy: 0.6439 - out_answer_type_procedure_accuracy: 0.7066 - out_answer_type_reason_explanation_accuracy: 0.5538 - out_answer_well_written_accuracy: 0.4790\n",
      "validation rho: 0.3195\n",
      "5471/5471 [==============================] - 428s 78ms/sample - loss: 27.2723 - out_question_asker_intent_understanding_loss: 1.2755 - out_question_body_critical_loss: 1.6628 - out_question_conversational_loss: 0.3207 - out_question_expect_short_answer_loss: 1.2583 - out_question_fact_seeking_loss: 0.9678 - out_question_has_commonly_accepted_answer_loss: 0.8794 - out_question_interestingness_others_loss: 1.5896 - out_question_interestingness_self_loss: 1.5499 - out_question_multi_intent_loss: 0.9320 - out_question_not_really_a_question_loss: 0.0618 - out_question_opinion_seeking_loss: 1.2214 - out_question_type_choice_loss: 0.8265 - out_question_type_compare_loss: 0.2267 - out_question_type_consequence_loss: 0.0947 - out_question_type_definition_loss: 0.1568 - out_question_type_entity_loss: 0.3436 - out_question_type_instructions_loss: 0.8551 - out_question_type_procedure_loss: 0.8925 - out_question_type_reason_explanation_loss: 1.0204 - out_question_type_spelling_loss: 0.0116 - out_question_well_written_loss: 1.6352 - out_answer_helpful_loss: 1.0973 - out_answer_level_of_information_loss: 1.0354 - out_answer_plausible_loss: 0.7635 - out_answer_relevance_loss: 0.6516 - out_answer_satisfaction_loss: 1.9303 - out_answer_type_instructions_loss: 0.9067 - out_answer_type_procedure_loss: 0.7990 - out_answer_type_reason_explanation_loss: 1.0763 - out_answer_well_written_loss: 1.2292 - out_question_asker_intent_understanding_accuracy: 0.4946 - out_question_body_critical_accuracy: 0.3522 - out_question_conversational_accuracy: 0.8945 - out_question_expect_short_answer_accuracy: 0.5025 - out_question_fact_seeking_accuracy: 0.6039 - out_question_has_commonly_accepted_answer_accuracy: 0.7158 - out_question_interestingness_others_accuracy: 0.3365 - out_question_interestingness_self_accuracy: 0.4069 - out_question_multi_intent_accuracy: 0.6388 - out_question_not_really_a_question_accuracy: 0.9892 - out_question_opinion_seeking_accuracy: 0.4560 - out_question_type_choice_accuracy: 0.6842 - out_question_type_compare_accuracy: 0.9313 - out_question_type_consequence_accuracy: 0.9792 - out_question_type_definition_accuracy: 0.9466 - out_question_type_entity_accuracy: 0.8903 - out_question_type_instructions_accuracy: 0.6701 - out_question_type_procedure_accuracy: 0.6518 - out_question_type_reason_explanation_accuracy: 0.5825 - out_question_type_spelling_accuracy: 0.9980 - out_question_well_written_accuracy: 0.3515 - out_answer_helpful_accuracy: 0.6138 - out_answer_level_of_information_accuracy: 0.6820 - out_answer_plausible_accuracy: 0.7752 - out_answer_relevance_accuracy: 0.8094 - out_answer_satisfaction_accuracy: 0.2795 - out_answer_type_instructions_accuracy: 0.6434 - out_answer_type_procedure_accuracy: 0.7068 - out_answer_type_reason_explanation_accuracy: 0.5538 - out_answer_well_written_accuracy: 0.4791\n",
      "Epoch 4/4\n",
      "5471/5471 [==============================] - 429s 78ms/sample - loss: 24.7614 - out_question_asker_intent_understanding_loss: 1.1816 - out_question_body_critical_loss: 1.5310 - out_question_conversational_loss: 0.2914 - out_question_expect_short_answer_loss: 1.1758 - out_question_fact_seeking_loss: 0.8775 - out_question_has_commonly_accepted_answer_loss: 0.7918 - out_question_interestingness_others_loss: 1.4778 - out_question_interestingness_self_loss: 1.4407 - out_question_multi_intent_loss: 0.8344 - out_question_not_really_a_question_loss: 0.0555 - out_question_opinion_seeking_loss: 1.1099 - out_question_type_choice_loss: 0.7319 - out_question_type_compare_loss: 0.1915 - out_question_type_consequence_loss: 0.0823 - out_question_type_definition_loss: 0.1336 - out_question_type_entity_loss: 0.2894 - out_question_type_instructions_loss: 0.7724 - out_question_type_procedure_loss: 0.8259 - out_question_type_reason_explanation_loss: 0.9149 - out_question_type_spelling_loss: 0.0089 - out_question_well_written_loss: 1.4945 - out_answer_helpful_loss: 0.9746 - out_answer_level_of_information_loss: 0.9082 - out_answer_plausible_loss: 0.6749 - out_answer_relevance_loss: 0.5713 - out_answer_satisfaction_loss: 1.7618 - out_answer_type_instructions_loss: 0.8188 - out_answer_type_procedure_loss: 0.7453 - out_answer_type_reason_explanation_loss: 0.9568 - out_answer_well_written_loss: 1.1368 - out_question_asker_intent_understanding_accuracy: 0.5279 - out_question_body_critical_accuracy: 0.4065 - out_question_conversational_accuracy: 0.8991 - out_question_expect_short_answer_accuracy: 0.5226 - out_question_fact_seeking_accuracy: 0.6326 - out_question_has_commonly_accepted_answer_accuracy: 0.7342 - out_question_interestingness_others_accuracy: 0.3957 - out_question_interestingness_self_accuracy: 0.4515 - out_question_multi_intent_accuracy: 0.6746 - out_question_not_really_a_question_accuracy: 0.9894 - out_question_opinion_seeking_accuracy: 0.5228 - out_question_type_choice_accuracy: 0.7123 - out_question_type_compare_accuracy: 0.9375 - out_question_type_consequence_accuracy: 0.9797 - out_question_type_definition_accuracy: 0.9559 - out_question_type_entity_accuracy: 0.9009 - out_question_type_instructions_accuracy: 0.6834 - out_question_type_procedure_accuracy: 0.6757 - out_question_type_reason_explanation_accuracy: 0.6209 - out_question_type_spelling_accuracy: 0.9980 - out_question_well_written_accuracy: 0.4118 - out_answer_helpful_accuracy: 0.6379 - out_answer_level_of_information_accuracy: 0.7079 - out_answer_plausible_accuracy: 0.7849 - out_answer_relevance_accuracy: 0.8141 - out_answer_satisfaction_accuracy: 0.3453 - out_answer_type_instructions_accuracy: 0.6750 - out_answer_type_procedure_accuracy: 0.7139 - out_answer_type_reason_explanation_accuracy: 0.6052 - out_answer_well_written_accuracy: 0.5239\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "#     print(len(train_idx), len(valid_idx))\n",
    "    if fold<3:\n",
    "        keras.backend.clear_session()\n",
    "        model = bertModel()\n",
    "        \n",
    "        train_inputs = [inputs[i][train_idx] for i in range(3)]\n",
    "        train_outputs = outputs[train_idx]\n",
    "\n",
    "        valid_inputs = [inputs[i][valid_idx] for i in range(3)]\n",
    "        valid_outputs = outputs[valid_idx]\n",
    "    \n",
    "        custom_callback = CustomCallback(val_size=len(valid_idx),valid_data=(valid_inputs, valid_outputs), test_data=test_inputs,\n",
    "                                         batch_size=8, fold=fold)\n",
    "        H = model.fit(train_inputs, [dum_cols['question_asker_intent_understanding'].iloc[train_idx,:].values,\n",
    " dum_cols['question_body_critical'].iloc[train_idx,:].values,\n",
    " dum_cols['question_conversational'].iloc[train_idx,:].values,\n",
    " dum_cols['question_expect_short_answer'].iloc[train_idx,:].values,\n",
    " dum_cols['question_fact_seeking'].iloc[train_idx,:].values,\n",
    " dum_cols['question_has_commonly_accepted_answer'].iloc[train_idx,:].values,\n",
    " dum_cols['question_interestingness_others'].iloc[train_idx,:].values,\n",
    " dum_cols['question_interestingness_self'].iloc[train_idx,:].values,\n",
    " dum_cols['question_multi_intent'].iloc[train_idx,:].values,\n",
    " dum_cols['question_not_really_a_question'].iloc[train_idx,:].values,\n",
    " dum_cols['question_opinion_seeking'].iloc[train_idx,:].values,\n",
    " dum_cols['question_type_choice'].iloc[train_idx,:].values,\n",
    " dum_cols['question_type_compare'].iloc[train_idx,:].values,\n",
    " dum_cols['question_type_consequence'].iloc[train_idx,:].values,\n",
    " dum_cols['question_type_definition'].iloc[train_idx,:].values,\n",
    " dum_cols['question_type_entity'].iloc[train_idx,:].values,\n",
    " dum_cols['question_type_instructions'].iloc[train_idx,:].values,\n",
    " dum_cols['question_type_procedure'].iloc[train_idx,:].values,\n",
    " dum_cols['question_type_reason_explanation'].iloc[train_idx,:].values,\n",
    " dum_cols['question_type_spelling'].iloc[train_idx,:].values,\n",
    " dum_cols['question_well_written'].iloc[train_idx,:].values,\n",
    " dum_cols['answer_helpful'].iloc[train_idx,:].values,\n",
    " dum_cols['answer_level_of_information'].iloc[train_idx,:].values,\n",
    " dum_cols['answer_plausible'].iloc[train_idx,:].values,\n",
    " dum_cols['answer_relevance'].iloc[train_idx,:].values,\n",
    " dum_cols['answer_satisfaction'].iloc[train_idx,:].values,\n",
    " dum_cols['answer_type_instructions'].iloc[train_idx,:].values,\n",
    " dum_cols['answer_type_procedure'].iloc[train_idx,:].values,\n",
    " dum_cols['answer_type_reason_explanation'].iloc[train_idx,:].values,\n",
    " dum_cols['answer_well_written'].iloc[train_idx,:].values], batch_size=8, epochs=4, verbose=1, callbacks=[custom_callback])\n",
    "        histories.append(H)        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sddzdfdvhfdgaggeggbsrdvsddfassfstrtryjymrtygcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = [test_predictions[i] for i in range(len(test_predictions))]\n",
    "test_preds = [np.average(test_preds[i], axis=0) for i in range(len(test_preds))]\n",
    "test_preds = np.mean(test_predictions, axis=0)\n",
    "\n",
    "df_sub.iloc[:, 1:] = test_preds\n",
    "\n",
    "df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zz = BertConfig.from_pretrained('../input/bert-tensorflow/bert-base-uncased-config.json',output_hidden_states=True)\n",
    "# class TFBertPreTrainedModel(TFPreTrainedModel):\n",
    "#     \"\"\" An abstract class to handle weights initialization and\n",
    "#         a simple interface for dowloading and loading pretrained models.\n",
    "#     \"\"\"\n",
    "\n",
    "#     config_class = zz\n",
    "#     pretrained_model_archive_map = {\"bert-base-uncased\": \"../input/bert-tensorflow/bert-base-uncased-tf_model.h5\"}\n",
    "#     base_model_prefix = \"bert\"\n",
    "\n",
    "\n",
    "# class TFBert_v2(TFBertPreTrainedModel):\n",
    "#     def __init__(self, config='../input/bert-tensorflow/bert-base-uncased-config.json', *inputs, **kwargs):\n",
    "#         self.config = config\n",
    "#         self.TF_BERT_PRETRAINED_MODEL_ARCHIVE_MAP = {\"bert-base-uncased\": \"../input/bert-tensorflow/bert-base-uncased-tf_model.h5\"}\n",
    "#         super(TFBert_v2, self).__init__(self.config, *inputs, **kwargs)\n",
    "#         self.bert = TFBertMainLayer(config, name=\"bert\")\n",
    "\n",
    "#     def call(self, inputs, **kwargs):\n",
    "#         outputs = self.bert(inputs, **kwargs)\n",
    "#         return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TFBertForSequenceClassification(TFBertPreTrainedModel):\n",
    "#     r\"\"\"\n",
    "#     Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n",
    "#         **logits**: ``Numpy array`` or ``tf.Tensor`` of shape ``(batch_size, config.num_labels)``\n",
    "#             Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
    "#         **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n",
    "#             list of ``Numpy array`` or ``tf.Tensor`` (one for the output of each layer + the output of the embeddings)\n",
    "#             of shape ``(batch_size, sequence_length, hidden_size)``:\n",
    "#             Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "#         **attentions**: (`optional`, returned when ``config.output_attentions=True``)\n",
    "#             list of ``Numpy array`` or ``tf.Tensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n",
    "#             Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
    "\n",
    "#     Examples::\n",
    "\n",
    "#         import tensorflow as tf\n",
    "#         from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "\n",
    "#         tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#         model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "#         input_ids = tf.constant(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True))[None, :]  # Batch size 1\n",
    "#         outputs = model(input_ids)\n",
    "#         logits = outputs[0]\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, config, *inputs, **kwargs):\n",
    "#         super(TFBertForSequenceClassification, self).__init__(config, *inputs, **kwargs)\n",
    "#         self.num_labels = config.num_labels\n",
    "\n",
    "#         self.bert = TFBertMainLayer(config, name=\"bert\")\n",
    "#         self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\n",
    "#         self.classifier = tf.keras.layers.Dense(\n",
    "#             config.num_labels, kernel_initializer=get_initializer(config.initializer_range), name=\"classifier\"\n",
    "#         )\n",
    "\n",
    "#     def call(self, inputs, **kwargs):\n",
    "#         outputs = self.bert(inputs, **kwargs)\n",
    "\n",
    "#         pooled_output = outputs[1]\n",
    "\n",
    "#         pooled_output = self.dropout(pooled_output, training=kwargs.get(\"training\", False))\n",
    "#         logits = self.classifier(pooled_output)\n",
    "\n",
    "#         outputs = (logits,) + outputs[1:]  # add pooled_output, hidden states and attention if they are here\n",
    "\n",
    "#         return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_config=BertConfig(unk_token=\"[QBODY]\", pad_token=\"[ANS]\").from_pretrained('../input/bert-tensorflow/bert-base-uncased-config.json',output_hidden_states=True, num_labels=1)\n",
    "# m = TFBertForSequenceClassification.from_pretrained(pretrained_model_name_or_path='../input/bert-tensorflow/bert-base-uncased-tf_model.h5', config = bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_config2=BertConfig(unk_token=\"[QBODY]\", pad_token=\"[ANS]\").from_pretrained('../input/bert-tensorflow/bert-base-uncased-config.json',output_hidden_states=True)\n",
    "# m2 = TFBertModel.from_pretrained(pretrained_model_name_or_path='../input/bert-tensorflow/bert-base-uncased-tf_model.h5', config = bert_config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input_ids=tf.constant(tokenizer2.encode(text=\"Hello, my dog is cute\", add_special_tokens=True))[None, :]  # Batch size 1\n",
    "# logits,pool, hidden_states = m(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input_ids=tf.constant(tokenizer2.encode(text=\"Hello, my dog is cute\", add_special_tokens=True))[None, :]  # Batch size 1\n",
    "# sequence_output, pooler_output, hidden_states2 = m2(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0ca032b33c6b4e80b87d8c3c1ac0a43d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c71800e28f245cb91d513f2968ef586": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_540b6a66e8304a24aa0e9940e7306fb6",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b535944608ea4e18b7feb64b71b18ae6",
       "value": 0
      }
     },
     "34a338d06a0640eab65790c02fe33287": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "540b6a66e8304a24aa0e9940e7306fb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "60179634e6a243aa950a6de086a6daa0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6af6d236ebd14aa4b0604846450d180d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2c71800e28f245cb91d513f2968ef586",
        "IPY_MODEL_db9b638f0b254dc08caa68e3a7a8f0eb"
       ],
       "layout": "IPY_MODEL_0ca032b33c6b4e80b87d8c3c1ac0a43d"
      }
     },
     "b535944608ea4e18b7feb64b71b18ae6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "db9b638f0b254dc08caa68e3a7a8f0eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_34a338d06a0640eab65790c02fe33287",
       "placeholder": "​",
       "style": "IPY_MODEL_60179634e6a243aa950a6de086a6daa0",
       "value": " 0/? [00:00&lt;?, ?it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
